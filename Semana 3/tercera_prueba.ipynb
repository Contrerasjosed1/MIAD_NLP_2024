{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdcRb56bDKlX"
      },
      "source": [
        "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NTzkK7UDKle"
      },
      "source": [
        "# Proyecto 1 - Predicción de precios de vehículos usados\n",
        "\n",
        "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desarrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
        "\n",
        "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
        "\n",
        "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/competitions/miad2024-12-prediccion-precio-vehiculos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMjkssSaDKlh"
      },
      "source": [
        "# Procesamiento y exploración preliminar de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mAyLUrhTDKlj"
      },
      "outputs": [],
      "source": [
        "# librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6XkvrmVuDKlm"
      },
      "outputs": [],
      "source": [
        "# cargar datos (se tiene en .csv en local)\n",
        "df_train=pd.read_csv(\"dataTrain_carListings.csv\")\n",
        "# data test tiene una columna llamada ID, que solamente es el orden de numeros\n",
        "df_test=pd.read_csv(\"dataTest_carListings.csv\", index_col=0)\n",
        "# Cargar datos reales\n",
        "df_real=pd.read_csv(\"true_car_listings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk8Fj1gdDKlw",
        "outputId": "9437b007-7093-475b-ba3e-a3182c43aa22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Price', 'Year', 'Mileage', 'State', 'Make', 'Model'], dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# eliminar columnas adicionales\n",
        "df_real.drop([\"City\", \"Vin\"], axis=1, inplace=True)\n",
        "df_real.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhcgCw7ctyX"
      },
      "source": [
        "## Entrenamiento y calibración de XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhcUcqfQXQWI",
        "outputId": "479d7db4-079f-4d7a-a05a-040e9afac283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\wendy\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DSRUgNBrieMx"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-w1SeBtj8DV",
        "outputId": "97249971-400c-4d0d-b00f-4b39934272ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400000 entries, 0 to 399999\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Price    400000 non-null  int64 \n",
            " 1   Year     400000 non-null  int64 \n",
            " 2   Mileage  400000 non-null  int64 \n",
            " 3   State    400000 non-null  object\n",
            " 4   Make     400000 non-null  object\n",
            " 5   Model    400000 non-null  object\n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 18.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nA7XBgKCj7Gz"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas\n",
        "categorical_columns = ['State', 'Make', 'Model']\n",
        "df_train = pd.get_dummies(df_train, columns=categorical_columns).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLdHctdRXQWL",
        "outputId": "6a18d770-6b7d-45eb-9054-7a5d4088c5c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de X_train: <class 'pandas.core.frame.DataFrame'>\n",
            "Tipo de X_test: <class 'pandas.core.frame.DataFrame'>\n",
            "Tipo de y_train: <class 'pandas.core.series.Series'>\n",
            "Tipo de y_test: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = df_train.drop(['Price'], axis=1)\n",
        "target = df_train['Price']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convertir los arrays resultantes en DataFrames de pandas\n",
        "X_train = pd.DataFrame(X_train, columns=data.columns)\n",
        "X_test = pd.DataFrame(X_test, columns=data.columns)\n",
        "y_train = pd.Series(y_train, name='Price')\n",
        "y_test = pd.Series(y_test, name='Price')\n",
        "\n",
        "# Verifica los tipos de datos de las estructuras resultantes\n",
        "print(\"Tipo de X_train:\", type(X_train))\n",
        "print(\"Tipo de X_test:\", type(X_test))\n",
        "print(\"Tipo de y_train:\", type(y_train))\n",
        "print(\"Tipo de y_test:\", type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "g7J8SxNkiWz8",
        "outputId": "0f589011-b729-4496-a074-d3d53c2a140e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Modelo sin calibrar\n",
        "xgb_1 = XGBRegressor(random_state=42)\n",
        "xgb_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxvytrwVip7w",
        "outputId": "2f4d25bd-c933-4c64-8279-c2881552c680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGBRegressor tiene un RMSE igual a 4266.196601029799 y un MAE igual a 3039.4960325634765\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento y desempeño del modelo XGBRegressor\n",
        "xgb_1.fit(X_train, y_train)\n",
        "y_pred = xgb_1.predict(X_test)\n",
        "# Calculo del MSE y el MAE\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"El modelo XGBRegressor tiene un RMSE igual a \" +str(rmse)+ \" y un MAE igual a \"+str(mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqU7V7HIgn-z",
        "outputId": "cf0cda62-ca39-45c9-8f32-6f6de0a5d6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in c:\\users\\wendy\\anaconda3\\lib\\site-packages (3.6.1)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
            "Requirement already satisfied: tqdm in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0dDtGC8h6Eq"
      },
      "source": [
        "## Prueba 1\n",
        "Fuente: https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 07:40:42,498] A new study created in memory with name: no-name-a23ec987-b57a-4531-83f1-fc4ab3a67689\n",
            "[I 2024-04-21 07:41:55,777] Trial 0 finished with value: 58266708.95231 and parameters: {'lambda': 1.971214082209539e-08, 'alpha': 3.891270848001614e-05, 'subsample': 0.9872978739878462, 'colsample_bytree': 0.30435408121285734, 'max_depth': 7, 'min_child_weight': 10, 'eta': 0.2503246399809418, 'gamma': 4.183199747011751e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 58266708.95231.\n",
            "[I 2024-04-21 07:42:52,876] Trial 1 finished with value: 115477217.75042 and parameters: {'lambda': 2.5542694568391625e-07, 'alpha': 0.021023971090472056, 'subsample': 0.4163091603186153, 'colsample_bytree': 0.32815543454051077, 'max_depth': 5, 'min_child_weight': 7, 'eta': 3.166134818504197e-06, 'gamma': 9.197166660721089e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 58266708.95231.\n",
            "[I 2024-04-21 07:44:10,687] Trial 2 finished with value: 29354150.29736 and parameters: {'lambda': 0.0006300622095494117, 'alpha': 0.00014622406232897364, 'subsample': 0.23255033200475195, 'colsample_bytree': 0.4885554959213272, 'max_depth': 9, 'min_child_weight': 8, 'eta': 0.7114903492018297, 'gamma': 6.252368056908203e-05, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:45:21,183] Trial 3 finished with value: 97934595.11232 and parameters: {'lambda': 0.7806265884505953, 'alpha': 0.015266744630197449, 'subsample': 0.8053494113088027, 'colsample_bytree': 0.512635196748753, 'max_depth': 3, 'min_child_weight': 4, 'eta': 0.04036554699450644, 'gamma': 2.9724266096190654e-07, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:46:37,427] Trial 4 finished with value: 115442594.69391 and parameters: {'lambda': 0.0759767618000462, 'alpha': 2.977454722520266e-07, 'subsample': 0.29524468384299063, 'colsample_bytree': 0.5854740900299943, 'max_depth': 3, 'min_child_weight': 6, 'eta': 6.202500665274083e-05, 'gamma': 0.0015459230558594699, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:47:44,499] Trial 5 finished with value: 115477217.75042 and parameters: {'lambda': 0.007864729929551286, 'alpha': 0.00013965751700469042, 'subsample': 0.21933887478571013, 'colsample_bytree': 0.20542734519815362, 'max_depth': 5, 'min_child_weight': 6, 'eta': 1.50349428840664e-06, 'gamma': 0.033775481774929235, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:48:48,511] Trial 6 finished with value: 115404117.70602 and parameters: {'lambda': 7.475163275835071e-05, 'alpha': 8.776592355948842e-05, 'subsample': 0.8362451153796344, 'colsample_bytree': 0.8472319856121995, 'max_depth': 5, 'min_child_weight': 7, 'eta': 8.956345121837675e-05, 'gamma': 0.1038773793749344, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:49:38,775] Trial 7 finished with value: 110847795.16587 and parameters: {'lambda': 0.004166913757215246, 'alpha': 3.7210071539333816e-08, 'subsample': 0.5155563981248215, 'colsample_bytree': 0.3771579740705246, 'max_depth': 9, 'min_child_weight': 10, 'eta': 0.006878550853048109, 'gamma': 4.878535424267403e-06, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:50:37,220] Trial 8 finished with value: 115415204.18679 and parameters: {'lambda': 0.015198801772613377, 'alpha': 0.397939151809, 'subsample': 0.36785648278329836, 'colsample_bytree': 0.49746041759791715, 'max_depth': 9, 'min_child_weight': 6, 'eta': 7.510935698945792e-05, 'gamma': 0.003064898236828904, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 29354150.29736.\n",
            "[I 2024-04-21 07:51:43,550] Trial 9 finished with value: 115477217.75042 and parameters: {'lambda': 0.044890860768732936, 'alpha': 7.909365895088591e-07, 'subsample': 0.26358712760764036, 'colsample_bytree': 0.3636632414433941, 'max_depth': 9, 'min_child_weight': 9, 'eta': 5.4213825195736435e-08, 'gamma': 1.4968104565753366e-05, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 29354150.29736.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  10\n",
            "Best trial:\n",
            "  Value: 29354150.29736\n",
            "  Params: \n",
            "    lambda: 0.0006300622095494117\n",
            "    alpha: 0.00014622406232897364\n",
            "    subsample: 0.23255033200475195\n",
            "    colsample_bytree: 0.4885554959213272\n",
            "    max_depth: 9\n",
            "    min_child_weight: 8\n",
            "    eta: 0.7114903492018297\n",
            "    gamma: 6.252368056908203e-05\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a 3781.8293587339426 y un MAE igual a 2485.5054897171785\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_calibrado = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.0006300622095494117,\n",
        "    alpha=0.00014622406232897364,\n",
        "    subsample=0.23255033200475195,\n",
        "    colsample_bytree=0.4885554959213272,\n",
        "    max_depth=9,\n",
        "    min_child_weight=8,\n",
        "    eta=0.7114903492018297,\n",
        "    gamma=6.252368056908203e-05,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_calibrado.fit(X_train, y_train)\n",
        "y_pred = xgb_calibrado.predict(X_test)\n",
        "mse_xgb_calibrado = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_calibrado = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_calibrado = np.sqrt(mse_xgb_calibrado)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_calibrado)+ \" y un MAE igual a \"+str(mae_xgb_calibrado))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 07:57:20,516] A new study created in memory with name: no-name-020af963-bbed-4a46-ad93-b4f8ed746878\n",
            "[I 2024-04-21 07:58:17,335] Trial 0 finished with value: 115451793.12943 and parameters: {'lambda': 0.20040150100119045, 'alpha': 1.6913496888892257e-05, 'subsample': 0.6862576039507055, 'colsample_bytree': 0.6193776455033985, 'max_depth': 5, 'min_child_weight': 8, 'eta': 3.593276220728275e-05, 'gamma': 2.1162184437348128e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 115451793.12943.\n",
            "[I 2024-04-21 07:59:09,854] Trial 1 finished with value: 115467205.22416 and parameters: {'lambda': 0.33238518085922236, 'alpha': 0.0035840099337023437, 'subsample': 0.7638912869257131, 'colsample_bytree': 0.4665646270373889, 'max_depth': 9, 'min_child_weight': 6, 'eta': 1.2251412424199472e-05, 'gamma': 0.3008654899419707, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 115451793.12943.\n",
            "[I 2024-04-21 07:59:54,080] Trial 2 finished with value: 114788166.83434 and parameters: {'lambda': 0.002928583448699068, 'alpha': 3.567191753192644e-05, 'subsample': 0.7916815604130127, 'colsample_bytree': 0.21656026011952312, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.0023043716287840035, 'gamma': 0.013924522944619886, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 114788166.83434.\n",
            "[I 2024-04-21 08:00:41,988] Trial 3 finished with value: 115477217.75042 and parameters: {'lambda': 0.12453886641300395, 'alpha': 3.9419667680698346e-07, 'subsample': 0.9882115589748703, 'colsample_bytree': 0.3238395437214281, 'max_depth': 3, 'min_child_weight': 10, 'eta': 6.216017758425262e-07, 'gamma': 5.5111312702907733e-08, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 114788166.83434.\n",
            "[I 2024-04-21 08:01:25,077] Trial 4 finished with value: 115477217.75042 and parameters: {'lambda': 0.00015971821968013616, 'alpha': 4.825025759320942e-07, 'subsample': 0.2728133599847487, 'colsample_bytree': 0.9723796147894632, 'max_depth': 5, 'min_child_weight': 8, 'eta': 2.916162287057425e-08, 'gamma': 0.0016747379041888778, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 114788166.83434.\n",
            "[I 2024-04-21 08:02:15,300] Trial 5 finished with value: 43500413.04606 and parameters: {'lambda': 6.495348499120076e-08, 'alpha': 0.03542309225742858, 'subsample': 0.42698884826807054, 'colsample_bytree': 0.46730993917370234, 'max_depth': 9, 'min_child_weight': 2, 'eta': 0.26837382433043583, 'gamma': 0.019887162244215672, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 43500413.04606.\n",
            "[I 2024-04-21 08:03:11,742] Trial 6 finished with value: 115463605.13575 and parameters: {'lambda': 0.2112908701199907, 'alpha': 1.5719856442039122e-07, 'subsample': 0.8468337821829315, 'colsample_bytree': 0.9152733877020771, 'max_depth': 9, 'min_child_weight': 2, 'eta': 1.2683896815562968e-05, 'gamma': 5.741666396558598e-06, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 43500413.04606.\n",
            "[I 2024-04-21 08:03:54,844] Trial 7 finished with value: 115477217.75042 and parameters: {'lambda': 4.053873826547283e-06, 'alpha': 4.528508484358865e-08, 'subsample': 0.34838126650804685, 'colsample_bytree': 0.497701729224519, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.322706669797072e-07, 'gamma': 0.0030588639130477895, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 43500413.04606.\n",
            "[I 2024-04-21 08:04:39,793] Trial 8 finished with value: 115450639.14802 and parameters: {'lambda': 0.014019587374302438, 'alpha': 0.9489212201452949, 'subsample': 0.4169591007289648, 'colsample_bytree': 0.5355182396002642, 'max_depth': 5, 'min_child_weight': 7, 'eta': 3.8681591428609176e-05, 'gamma': 2.8301309007722974e-08, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 43500413.04606.\n",
            "[I 2024-04-21 08:05:24,405] Trial 9 finished with value: 104703805.28621 and parameters: {'lambda': 1.7439786645041223e-08, 'alpha': 0.14941142914032246, 'subsample': 0.8216977481741061, 'colsample_bytree': 0.5385769454010068, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.015408098120671341, 'gamma': 2.3996899266094217e-06, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 43500413.04606.\n",
            "[I 2024-04-21 08:06:10,939] Trial 10 finished with value: 25131732.68879 and parameters: {'lambda': 1.3618109137815986e-08, 'alpha': 0.0068473212560469085, 'subsample': 0.5383447526406704, 'colsample_bytree': 0.7375702235448874, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.925350157501082, 'gamma': 0.8591307262185451, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 25131732.68879.\n",
            "[I 2024-04-21 08:06:57,286] Trial 11 finished with value: 27311532.66045 and parameters: {'lambda': 1.0398660739717807e-08, 'alpha': 0.004888254453971415, 'subsample': 0.500607586115732, 'colsample_bytree': 0.7635288738967634, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.7403802397101047, 'gamma': 0.5068557722119172, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 25131732.68879.\n",
            "[I 2024-04-21 08:07:41,728] Trial 12 finished with value: 26184202.9495 and parameters: {'lambda': 8.294576117822705e-07, 'alpha': 0.003081848552777191, 'subsample': 0.5742418083939129, 'colsample_bytree': 0.7721068996980154, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.9827138795569503, 'gamma': 0.883390841997928, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 25131732.68879.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  13\n",
            "Best trial:\n",
            "  Value: 25131732.68879\n",
            "  Params: \n",
            "    lambda: 1.3618109137815986e-08\n",
            "    alpha: 0.0068473212560469085\n",
            "    subsample: 0.5383447526406704\n",
            "    colsample_bytree: 0.7375702235448874\n",
            "    max_depth: 9\n",
            "    min_child_weight: 4\n",
            "    eta: 0.925350157501082\n",
            "    gamma: 0.8591307262185451\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "# Intento #2 agregando más ensayos\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a 3799.748768198024 y un MAE igual a 2402.751549249878\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_cal = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=1.3618109137815986e-08,\n",
        "    alpha=0.0068473212560469085,\n",
        "    subsample=0.5383447526406704,\n",
        "    colsample_bytree=0.7375702235448874,\n",
        "    max_depth=9,\n",
        "    min_child_weight=4,\n",
        "    eta=0.925350157501082,\n",
        "    gamma=0.8591307262185451,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_cal.fit(X_train, y_train)\n",
        "y_pred = xgb_cal.predict(X_test)\n",
        "mse_xgb_cal = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_cal = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_cal = np.sqrt(mse_xgb_cal)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_cal)+ \" y un MAE igual a \"+str(mae_xgb_cal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 08:17:11,925] A new study created in memory with name: no-name-e423e33d-9a4e-4db2-9856-f6b38c66cf1a\n",
            "[I 2024-04-21 08:18:26,033] Trial 0 finished with value: 115405549.16559 and parameters: {'lambda': 8.483891491275393e-07, 'alpha': 0.04049792107786824, 'subsample': 0.5061438255278877, 'colsample_bytree': 0.9132630822622902, 'n_estimators': 719, 'max_depth': 7, 'min_child_weight': 6, 'eta': 7.218397156833382e-05, 'gamma': 1.012252817923622e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 115405549.16559.\n",
            "[I 2024-04-21 08:19:21,170] Trial 1 finished with value: 115477217.75042 and parameters: {'lambda': 0.0006005291991613236, 'alpha': 0.007290525723887676, 'subsample': 0.5667400033442328, 'colsample_bytree': 0.9848274047218768, 'n_estimators': 214, 'max_depth': 9, 'min_child_weight': 10, 'eta': 2.919252606518446e-07, 'gamma': 4.14051509102989e-08, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 115405549.16559.\n",
            "[I 2024-04-21 08:20:12,515] Trial 2 finished with value: 115473221.83833 and parameters: {'lambda': 9.077476405166318e-06, 'alpha': 0.1968929264656639, 'subsample': 0.9495968132100627, 'colsample_bytree': 0.4415333892219484, 'n_estimators': 596, 'max_depth': 7, 'min_child_weight': 4, 'eta': 6.6254204614361895e-06, 'gamma': 0.4089557470196288, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 115405549.16559.\n",
            "[I 2024-04-21 08:21:01,026] Trial 3 finished with value: 115477217.75042 and parameters: {'lambda': 0.0014995107098214721, 'alpha': 0.003979148817602751, 'subsample': 0.8959173077317197, 'colsample_bytree': 0.4606506511433714, 'n_estimators': 346, 'max_depth': 5, 'min_child_weight': 7, 'eta': 2.233249145890427e-08, 'gamma': 0.04496347995107441, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 115405549.16559.\n",
            "[I 2024-04-21 08:21:50,937] Trial 4 finished with value: 113178449.79399 and parameters: {'lambda': 1.1529055409477825e-08, 'alpha': 0.0006632134084632915, 'subsample': 0.9452654057384071, 'colsample_bytree': 0.3405632878014436, 'n_estimators': 620, 'max_depth': 7, 'min_child_weight': 3, 'eta': 0.004031492898756663, 'gamma': 0.00030071026268376844, 'grow_policy': 'depthwise'}. Best is trial 4 with value: 113178449.79399.\n",
            "[I 2024-04-21 08:22:34,914] Trial 5 finished with value: 64898470.76185 and parameters: {'lambda': 0.15390016365254441, 'alpha': 0.02017652841544522, 'subsample': 0.6182484542262087, 'colsample_bytree': 0.7535105326593909, 'n_estimators': 905, 'max_depth': 3, 'min_child_weight': 7, 'eta': 0.2844283319770303, 'gamma': 2.7170163586772176e-05, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 64898470.76185.\n",
            "[I 2024-04-21 08:23:25,903] Trial 6 finished with value: 115477217.75042 and parameters: {'lambda': 0.00039274861982302163, 'alpha': 3.548934782692428e-08, 'subsample': 0.6713733066775879, 'colsample_bytree': 0.7314422829521263, 'n_estimators': 620, 'max_depth': 7, 'min_child_weight': 6, 'eta': 2.8820350468448707e-07, 'gamma': 0.7116905488595584, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 64898470.76185.\n",
            "[I 2024-04-21 08:24:09,211] Trial 7 finished with value: 114937324.97546 and parameters: {'lambda': 0.0006289748810084239, 'alpha': 0.8843284505906501, 'subsample': 0.9620288994590174, 'colsample_bytree': 0.21155551870845477, 'n_estimators': 178, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.002068898461640954, 'gamma': 1.1764804243280821e-05, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 64898470.76185.\n",
            "[I 2024-04-21 08:25:00,826] Trial 8 finished with value: 115440441.32193 and parameters: {'lambda': 0.020052754534482933, 'alpha': 4.051625654108083e-05, 'subsample': 0.8851731090172283, 'colsample_bytree': 0.603760891221002, 'n_estimators': 561, 'max_depth': 3, 'min_child_weight': 10, 'eta': 6.699134905074207e-05, 'gamma': 0.10436236799451207, 'grow_policy': 'lossguide'}. Best is trial 5 with value: 64898470.76185.\n",
            "[I 2024-04-21 08:25:46,594] Trial 9 finished with value: 115455620.92265 and parameters: {'lambda': 0.12363942674878725, 'alpha': 0.0011366890729871799, 'subsample': 0.2536572463392632, 'colsample_bytree': 0.8083849795258993, 'n_estimators': 570, 'max_depth': 7, 'min_child_weight': 4, 'eta': 2.314021195067647e-05, 'gamma': 4.9771234712589874e-05, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 64898470.76185.\n",
            "[I 2024-04-21 08:26:28,575] Trial 10 finished with value: 48731400.13417 and parameters: {'lambda': 0.6195038142364203, 'alpha': 1.221194991813637e-05, 'subsample': 0.38894839997158176, 'colsample_bytree': 0.6630454547081536, 'n_estimators': 978, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.9523461599907942, 'gamma': 0.001495293621003925, 'grow_policy': 'depthwise'}. Best is trial 10 with value: 48731400.13417.\n",
            "[I 2024-04-21 08:27:08,935] Trial 11 finished with value: 48109879.88691 and parameters: {'lambda': 0.6699372643191684, 'alpha': 6.573622084748475e-06, 'subsample': 0.39647758222476603, 'colsample_bytree': 0.6746881349608689, 'n_estimators': 991, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.924519607479056, 'gamma': 0.002916079152852752, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 48109879.88691.\n",
            "[I 2024-04-21 08:27:52,403] Trial 12 finished with value: 47623586.62675 and parameters: {'lambda': 0.9501091374676599, 'alpha': 2.2458201898736107e-06, 'subsample': 0.33554148719968135, 'colsample_bytree': 0.6131209517619073, 'n_estimators': 988, 'max_depth': 3, 'min_child_weight': 8, 'eta': 0.9710181349940284, 'gamma': 0.0031652899319421076, 'grow_policy': 'depthwise'}. Best is trial 12 with value: 47623586.62675.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  13\n",
            "Best trial:\n",
            "  Value: 47623586.62675\n",
            "  Params: \n",
            "    lambda: 0.9501091374676599\n",
            "    alpha: 2.2458201898736107e-06\n",
            "    subsample: 0.33554148719968135\n",
            "    colsample_bytree: 0.6131209517619073\n",
            "    n_estimators: 988\n",
            "    max_depth: 3\n",
            "    min_child_weight: 8\n",
            "    eta: 0.9710181349940284\n",
            "    gamma: 0.0031652899319421076\n",
            "    grow_policy: depthwise\n"
          ]
        }
      ],
      "source": [
        "# intento # 3, agregando el parámetro n_estimators\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "        # número de árboles en el ensamble\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando Optuna tiene un RMSE igual a 3670.867236378481 y un MAE igual a 2405.6893865302277\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_cal_2 = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.9501091374676599,\n",
        "    alpha=2.2458201898736107e-06,\n",
        "    subsample=0.33554148719968135,\n",
        "    colsample_bytree=0.6131209517619073,\n",
        "    n_estimators= 988,\n",
        "    max_depth=3,\n",
        "    min_child_weight=8,\n",
        "    eta=0.9710181349940284,\n",
        "    gamma=0.0031652899319421076,\n",
        "    grow_policy='depthwise',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_cal_2.fit(X_train, y_train)\n",
        "y_pred = xgb_cal_2.predict(X_test)\n",
        "mse_xgb_cal_2 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_cal_2 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_cal_2 = np.sqrt(mse_xgb_cal_2)\n",
        "print(\"El modelo XGB calibrado usando Optuna tiene un RMSE igual a \" +str(rmse_xgb_cal_2)+ \" y un MAE igual a \"+str(mae_xgb_cal_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 08:46:29,488] A new study created in memory with name: no-name-30e1af46-eca3-4406-89bb-0fda57c665e7\n",
            "[I 2024-04-21 08:47:46,924] Trial 0 finished with value: 99690658.93237 and parameters: {'lambda': 1.881540728677821e-07, 'alpha': 0.017905189484565296, 'subsample': 0.9691611843188477, 'colsample_bytree': 0.6726434557487605, 'n_estimators': 121, 'max_depth': 9, 'min_child_weight': 7, 'eta': 0.01891843984008906, 'gamma': 0.0006103913174070533, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:48:34,915] Trial 1 finished with value: 115420571.60924 and parameters: {'lambda': 0.03395876280124672, 'alpha': 0.00036198987123090963, 'subsample': 0.9084870230740569, 'colsample_bytree': 0.21853901055694616, 'n_estimators': 948, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.00027044891973931076, 'gamma': 0.002081607944394096, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:49:20,296] Trial 2 finished with value: 114907961.65444 and parameters: {'lambda': 5.2201831956519635e-06, 'alpha': 1.8662813467069008e-08, 'subsample': 0.6177572582431852, 'colsample_bytree': 0.26515461479004676, 'n_estimators': 146, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.0014734680837538857, 'gamma': 0.2622497047611222, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:50:02,415] Trial 3 finished with value: 113646324.24499 and parameters: {'lambda': 0.047908154861661466, 'alpha': 1.2581003015165857e-07, 'subsample': 0.33677400006588165, 'colsample_bytree': 0.2995164574297074, 'n_estimators': 891, 'max_depth': 3, 'min_child_weight': 9, 'eta': 0.005769112434084017, 'gamma': 7.013093186367959e-06, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:50:53,070] Trial 4 finished with value: 115460684.44762 and parameters: {'lambda': 0.0006955386965428626, 'alpha': 6.496596927247243e-07, 'subsample': 0.9125845787178395, 'colsample_bytree': 0.6867200801026467, 'n_estimators': 493, 'max_depth': 5, 'min_child_weight': 7, 'eta': 2.3002233895943803e-05, 'gamma': 0.17258999807063904, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:51:42,995] Trial 5 finished with value: 115477217.75042 and parameters: {'lambda': 2.350306094362379e-08, 'alpha': 9.923657035460069e-08, 'subsample': 0.9498771893952354, 'colsample_bytree': 0.9623497043932188, 'n_estimators': 324, 'max_depth': 7, 'min_child_weight': 2, 'eta': 9.617320230881215e-08, 'gamma': 1.4493702255706384e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:52:28,126] Trial 6 finished with value: 115477217.75042 and parameters: {'lambda': 0.008016925658711148, 'alpha': 2.7468708792427775e-07, 'subsample': 0.8908139072408958, 'colsample_bytree': 0.45666324747196074, 'n_estimators': 278, 'max_depth': 7, 'min_child_weight': 7, 'eta': 9.981355573985963e-08, 'gamma': 1.0908731151545842e-05, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 99690658.93237.\n",
            "[I 2024-04-21 08:53:26,507] Trial 7 finished with value: 99506303.71775 and parameters: {'lambda': 1.8298627778599665e-07, 'alpha': 0.0006957963563365393, 'subsample': 0.43721264623826994, 'colsample_bytree': 0.9318475730841598, 'n_estimators': 885, 'max_depth': 7, 'min_child_weight': 7, 'eta': 0.019091401498895526, 'gamma': 2.032165394640574e-05, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 99506303.71775.\n",
            "[I 2024-04-21 08:54:40,948] Trial 8 finished with value: 115355864.55314 and parameters: {'lambda': 0.10112905449590608, 'alpha': 0.4521396210809671, 'subsample': 0.8975236167097671, 'colsample_bytree': 0.8379849476979351, 'n_estimators': 311, 'max_depth': 3, 'min_child_weight': 10, 'eta': 0.00018365906005537574, 'gamma': 9.898129735675402, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 99506303.71775.\n",
            "[I 2024-04-21 08:55:30,646] Trial 9 finished with value: 115477217.75042 and parameters: {'lambda': 1.8431702422787938e-05, 'alpha': 0.0002918416056682448, 'subsample': 0.6617039635796742, 'colsample_bytree': 0.5557177522359626, 'n_estimators': 427, 'max_depth': 5, 'min_child_weight': 4, 'eta': 5.298502334348937e-08, 'gamma': 3.9972302169019454, 'grow_policy': 'lossguide'}. Best is trial 7 with value: 99506303.71775.\n",
            "[I 2024-04-21 08:56:23,708] Trial 10 finished with value: 27412635.58276 and parameters: {'lambda': 7.509717620410748e-07, 'alpha': 1.3586388225813745e-05, 'subsample': 0.2155865607201664, 'colsample_bytree': 0.9813729597904707, 'n_estimators': 728, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.8573247591873945, 'gamma': 1.298919176552225e-08, 'grow_policy': 'lossguide'}. Best is trial 10 with value: 27412635.58276.\n",
            "[I 2024-04-21 08:57:16,209] Trial 11 finished with value: 26722531.74245 and parameters: {'lambda': 9.564561673448604e-07, 'alpha': 1.6980413730845048e-05, 'subsample': 0.2288913151339783, 'colsample_bytree': 0.9932758875637113, 'n_estimators': 699, 'max_depth': 9, 'min_child_weight': 5, 'eta': 0.9676347877899362, 'gamma': 1.115418460534174e-08, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 26722531.74245.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  12\n",
            "Best trial:\n",
            "  Value: 26722531.74245\n",
            "  Params: \n",
            "    lambda: 9.564561673448604e-07\n",
            "    alpha: 1.6980413730845048e-05\n",
            "    subsample: 0.2288913151339783\n",
            "    colsample_bytree: 0.9932758875637113\n",
            "    n_estimators: 699\n",
            "    max_depth: 9\n",
            "    min_child_weight: 5\n",
            "    eta: 0.9676347877899362\n",
            "    gamma: 1.115418460534174e-08\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "# Intento #4 cambiando los valores del parámetro gamma\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "        # número de árboles en el ensamble\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 500, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando Optuna tiene un RMSE igual a 3670.867236378481 y un MAE igual a 3129.3654176013756\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_2 = XGBRegressor(\n",
        "    reg_lambda=9.564561673448604e-07,\n",
        "    alpha=1.6980413730845048e-05,\n",
        "    subsample=0.2288913151339783,\n",
        "    colsample_bytree=0.9932758875637113,\n",
        "    n_estimators= 699,\n",
        "    max_depth=9,\n",
        "    min_child_weight=5,\n",
        "    eta=0.9676347877899362,\n",
        "    gamma=1.115418460534174e-08,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_2.fit(X_train, y_train)\n",
        "y_pred = xgb_2.predict(X_test)\n",
        "mse_xgb_2 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_2 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_2 = np.sqrt(mse_xgb_2)\n",
        "print(\"El modelo XGB calibrado usando Optuna tiene un RMSE igual a \" +str(rmse_xgb_2)+ \" y un MAE igual a \"+str(mae_xgb_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "# Calibración de gamma\n",
        "gamma = np.arange(0, 100, 10 )\n",
        "MSE_2 = []\n",
        "for valor in gamma:\n",
        "    xgb = XGBRegressor(gamma=valor, random_state=1)\n",
        "    MSE_2.append(cross_val_score(xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
        "    MSE_2 = [abs(valor) for valor in MSE_2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(gamma, MSE_2)\n",
        "plt.title(\"Desempeño de XGBoost por cada valor de gamma\")\n",
        "plt.xlabel('gamma')\n",
        "plt.ylabel('MSE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cargar predicciones en Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuaaUkJnXQWU",
        "outputId": "059224b3-14e9-479a-b522-fc0cbb689d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 300000 entries, 34894 to 121958\n",
            "Columns: 616 entries, Year to Model_xD5dr\n",
            "dtypes: int32(616)\n",
            "memory usage: 707.2 MB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJknYwT_XQWV",
        "outputId": "1428c820-2146-481a-b6a9-aad3d5bdcc41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Mileage', 'State_ AK', 'State_ AL', 'State_ AR', 'State_ AZ',\n",
              "       'State_ CA', 'State_ CO', 'State_ CT', 'State_ DC',\n",
              "       ...\n",
              "       'Model_Yaris4dr', 'Model_YarisBase', 'Model_YarisLE', 'Model_Yukon',\n",
              "       'Model_Yukon2WD', 'Model_Yukon4WD', 'Model_Yukon4dr', 'Model_tC2dr',\n",
              "       'Model_xB5dr', 'Model_xD5dr'],\n",
              "      dtype='object', length=616)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH273Up_XQWd"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas en df_test\n",
        "df_test_ = pd.get_dummies(df_test, columns=categorical_columns).astype(int)\n",
        "\n",
        "# Alinear las columnas de df_test con X_train\n",
        "df_test_aligned, _ = df_test_.align(X_train, axis=1, fill_value=0)\n",
        "\n",
        "column_order = X_train.columns.tolist()\n",
        "\n",
        "# Reordenar las columnas de df_test_aligned de acuerdo con el orden en X_train\n",
        "df_test_ordenado = df_test_aligned[column_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR6rRk4vXQWe",
        "outputId": "ecc6eb21-29f7-4694-fd91-2b476265db41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Mileage', 'State_ AK', 'State_ AL', 'State_ AR', 'State_ AZ',\n",
              "       'State_ CA', 'State_ CO', 'State_ CT', 'State_ DC',\n",
              "       ...\n",
              "       'Model_Yaris4dr', 'Model_YarisBase', 'Model_YarisLE', 'Model_Yukon',\n",
              "       'Model_Yukon2WD', 'Model_Yukon4WD', 'Model_Yukon4dr', 'Model_tC2dr',\n",
              "       'Model_xB5dr', 'Model_xD5dr'],\n",
              "      dtype='object', length=616)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test_ordenado.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKmJBGdVXQWf"
      },
      "outputs": [],
      "source": [
        "# Se usa df_test_aligned para predecir\n",
        "y_pred = xgb_calibrado_3.predict(df_test_ordenado)\n",
        "\n",
        "predictions_df = pd.DataFrame(y_pred, index=df_test_ordenado.index, columns=['Price'])\n",
        "\n",
        "predictions_df.to_csv('predicciones.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4usiAcIJXQWg",
        "outputId": "f23f280f-6cae-4d60-bd89-10708ed029b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a 3767.236427865088 y un MAE igual a 2456.755887738342\n"
          ]
        }
      ],
      "source": [
        "# El modelo montado en Kaggle fue:\n",
        "xgb_calibrado_3 = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.30212357583678445,\n",
        "    alpha=0.18211410327397226,\n",
        "    subsample=0.3521449713976327,\n",
        "    colsample_bytree=0.44811953613366806,\n",
        "    max_depth=9,\n",
        "    min_child_weight=9,\n",
        "    eta=0.8918833748094722,\n",
        "    gamma=0.00034064735565798957,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1  # Si deseas mantener una semilla aleatoria fija\n",
        ")\n",
        "xgb_calibrado_3.fit(X_train, y_train)\n",
        "y_pred = xgb_calibrado_3.predict(X_test)\n",
        "mse_xgb_calibrado_3 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_calibrado_3 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_calibrado_3 = np.sqrt(mse_xgb_calibrado_3)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_calibrado_3)+ \" y un MAE igual a \"+str(mae_xgb_calibrado_3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
