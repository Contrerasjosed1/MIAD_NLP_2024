{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdcRb56bDKlX"
      },
      "source": [
        "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NTzkK7UDKle"
      },
      "source": [
        "# Proyecto 1 - Predicción de precios de vehículos usados\n",
        "\n",
        "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desarrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
        "\n",
        "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
        "\n",
        "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/competitions/miad2024-12-prediccion-precio-vehiculos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMjkssSaDKlh"
      },
      "source": [
        "# Procesamiento y exploración preliminar de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mAyLUrhTDKlj"
      },
      "outputs": [],
      "source": [
        "# librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6XkvrmVuDKlm"
      },
      "outputs": [],
      "source": [
        "# cargar datos (se tiene en .csv en local)\n",
        "df_train=pd.read_csv(\"dataTrain_carListings.csv\")\n",
        "# data test tiene una columna llamada ID, que solamente es el orden de numeros\n",
        "df_test=pd.read_csv(\"dataTest_carListings.csv\", index_col=0)\n",
        "# Cargar datos reales\n",
        "# df_real=pd.read_csv(\"true_car_listings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk8Fj1gdDKlw",
        "outputId": "9437b007-7093-475b-ba3e-a3182c43aa22"
      },
      "outputs": [],
      "source": [
        "# eliminar columnas adicionales\n",
        "# df_real.drop([\"City\", \"Vin\"], axis=1, inplace=True)\n",
        "# df_real.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhcgCw7ctyX"
      },
      "source": [
        "## Entrenamiento y calibración de XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhcUcqfQXQWI",
        "outputId": "479d7db4-079f-4d7a-a05a-040e9afac283"
      },
      "outputs": [],
      "source": [
        "# pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DSRUgNBrieMx"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-w1SeBtj8DV",
        "outputId": "97249971-400c-4d0d-b00f-4b39934272ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400000 entries, 0 to 399999\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Price    400000 non-null  int64 \n",
            " 1   Year     400000 non-null  int64 \n",
            " 2   Mileage  400000 non-null  int64 \n",
            " 3   State    400000 non-null  object\n",
            " 4   Make     400000 non-null  object\n",
            " 5   Model    400000 non-null  object\n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 18.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nA7XBgKCj7Gz"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas\n",
        "categorical_columns = ['State', 'Make', 'Model']\n",
        "df_train = pd.get_dummies(df_train, columns=categorical_columns).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLdHctdRXQWL",
        "outputId": "6a18d770-6b7d-45eb-9054-7a5d4088c5c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de X_train: <class 'pandas.core.frame.DataFrame'>\n",
            "Tipo de X_test: <class 'pandas.core.frame.DataFrame'>\n",
            "Tipo de y_train: <class 'pandas.core.series.Series'>\n",
            "Tipo de y_test: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = df_train.drop(['Price'], axis=1)\n",
        "target = df_train['Price']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convertir los arrays resultantes en DataFrames de pandas\n",
        "X_train = pd.DataFrame(X_train, columns=data.columns)\n",
        "X_test = pd.DataFrame(X_test, columns=data.columns)\n",
        "y_train = pd.Series(y_train, name='Price')\n",
        "y_test = pd.Series(y_test, name='Price')\n",
        "\n",
        "# Verifica los tipos de datos de las estructuras resultantes\n",
        "print(\"Tipo de X_train:\", type(X_train))\n",
        "print(\"Tipo de X_test:\", type(X_test))\n",
        "print(\"Tipo de y_train:\", type(y_train))\n",
        "print(\"Tipo de y_test:\", type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-25 09:17:05,749] A new study created in memory with name: no-name-e203564a-4421-4133-b0a3-d5e6558a7189\n",
            "[I 2024-04-25 09:27:34,852] Trial 0 finished with value: 6249.331659738671 and parameters: {'n_estimators': 93, 'max_samples': 0.801568164623271, 'max_features': 0.5184037757417734, 'bootstrap': True, 'bootstrap_features': True, 'warm_start': False}. Best is trial 0 with value: 6249.331659738671.\n",
            "[I 2024-04-25 09:41:45,557] Trial 1 finished with value: 4621.955223673426 and parameters: {'n_estimators': 79, 'max_samples': 0.5156798312823754, 'max_features': 0.8994471249644933, 'bootstrap': False, 'bootstrap_features': True, 'warm_start': False}. Best is trial 1 with value: 4621.955223673426.\n",
            "[I 2024-04-25 09:58:29,754] Trial 2 finished with value: 4476.08850019158 and parameters: {'n_estimators': 62, 'max_samples': 0.5486829558076504, 'max_features': 0.6153976469360052, 'bootstrap': True, 'bootstrap_features': False, 'warm_start': False}. Best is trial 2 with value: 4476.08850019158.\n",
            "[I 2024-04-25 10:07:07,502] Trial 3 finished with value: 4589.633598118224 and parameters: {'n_estimators': 38, 'max_samples': 0.6565325541594016, 'max_features': 0.9436084764450238, 'bootstrap': False, 'bootstrap_features': True, 'warm_start': False}. Best is trial 2 with value: 4476.08850019158.\n",
            "[I 2024-04-25 10:13:44,389] Trial 4 finished with value: 4645.927232324223 and parameters: {'n_estimators': 33, 'max_samples': 0.5988057285564719, 'max_features': 0.9263582624607527, 'bootstrap': False, 'bootstrap_features': True, 'warm_start': False}. Best is trial 2 with value: 4476.08850019158.\n",
            "[I 2024-04-25 10:30:30,754] Trial 5 finished with value: 5255.113717587668 and parameters: {'n_estimators': 100, 'max_samples': 0.8266613637750367, 'max_features': 0.713172031147189, 'bootstrap': True, 'bootstrap_features': True, 'warm_start': True}. Best is trial 2 with value: 4476.08850019158.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros: {'n_estimators': 62, 'max_samples': 0.5486829558076504, 'max_features': 0.6153976469360052, 'bootstrap': True, 'bootstrap_features': False, 'warm_start': False}\n",
            "Mejor RMSE obtenido: 4476.08850019158\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingRegressor(max_features=0.6153976469360052,\n",
              "                 max_samples=0.5486829558076504, n_estimators=62,\n",
              "                 random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(max_features=0.6153976469360052,\n",
              "                 max_samples=0.5486829558076504, n_estimators=62,\n",
              "                 random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "BaggingRegressor(max_features=0.6153976469360052,\n",
              "                 max_samples=0.5486829558076504, n_estimators=62,\n",
              "                 random_state=42)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Función objetivo para la optimización\n",
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Función objetivo para la optimización\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 100)\n",
        "    max_samples = trial.suggest_float(\"max_samples\", 0.5, 1.0)\n",
        "    max_features = trial.suggest_float(\"max_features\", 0.5, 1.0)\n",
        "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
        "    bootstrap_features = trial.suggest_categorical(\"bootstrap_features\", [True, False])\n",
        "    warm_start = trial.suggest_categorical(\"warm_start\", [True, False])\n",
        "    \n",
        "    reg = BaggingRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_samples=max_samples,\n",
        "        max_features=max_features,\n",
        "        bootstrap=bootstrap,\n",
        "        bootstrap_features=bootstrap_features,\n",
        "        warm_start=warm_start,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    reg.fit(X_train, y_train)\n",
        "    y_pred = reg.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    return rmse\n",
        "\n",
        "# Crear y ejecutar el estudio de optimización con un límite de tiempo\n",
        "study = optuna.create_study(direction=\"minimize\")  # Cambio a minimize porque queremos minimizar RMSE\n",
        "study.optimize(objective, n_trials=100, timeout=3600)  # Límite de tiempo de 1 hora\n",
        "\n",
        "# Resultados\n",
        "print(\"Mejores parámetros:\", study.best_params)\n",
        "print(\"Mejor RMSE obtenido:\", study.best_value)\n",
        "\n",
        "# Configuración del modelo con los mejores parámetros\n",
        "best_reg = BaggingRegressor(\n",
        "    n_estimators=study.best_params['n_estimators'],\n",
        "    max_samples=study.best_params['max_samples'],\n",
        "    max_features=study.best_params['max_features'],\n",
        "    bootstrap=study.best_params['bootstrap'],\n",
        "    bootstrap_features=study.best_params['bootstrap_features'],\n",
        "    warm_start=study.best_params['warm_start'],\n",
        "    random_state=42\n",
        ")\n",
        "best_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# El modelo está listo para ser usado o evaluado más detalladamente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-25 12:00:18,354] A new study created in memory with name: no-name-c6093811-fa8d-4333-92ab-9ca09d783c90\n",
            "[I 2024-04-25 12:00:32,646] Trial 0 finished with value: 6107.411781863169 and parameters: {'n_estimators': 108, 'max_depth': 5, 'min_child_weight': 7, 'gamma': 0.32818886251806256, 'learning_rate': 0.07659074397579649, 'subsample': 0.7285260770421705, 'colsample_bytree': 0.594034521742388, 'lambda': 0.02053595551720402, 'alpha': 1.0386149535617004, 'scale_pos_weight': 61.525616251564394}. Best is trial 0 with value: 6107.411781863169.\n",
            "[I 2024-04-25 12:01:39,316] Trial 1 finished with value: 3555.7563794012485 and parameters: {'n_estimators': 592, 'max_depth': 7, 'min_child_weight': 4, 'gamma': 0.8944539791912829, 'learning_rate': 0.13951754102998098, 'subsample': 0.7811533302283751, 'colsample_bytree': 0.902414643116183, 'lambda': 0.0010490887048911982, 'alpha': 0.08070787874148855, 'scale_pos_weight': 94.04380293979686}. Best is trial 1 with value: 3555.7563794012485.\n",
            "[I 2024-04-25 12:02:49,766] Trial 2 finished with value: 3531.638497030028 and parameters: {'n_estimators': 572, 'max_depth': 13, 'min_child_weight': 10, 'gamma': 0.6607445888133439, 'learning_rate': 0.0769905676853471, 'subsample': 0.9087354770864895, 'colsample_bytree': 0.6456092067214454, 'lambda': 0.036189951407000626, 'alpha': 0.005317935173080457, 'scale_pos_weight': 9.689356200790769}. Best is trial 2 with value: 3531.638497030028.\n",
            "[I 2024-04-25 12:03:54,891] Trial 3 finished with value: 3484.9134377472506 and parameters: {'n_estimators': 753, 'max_depth': 13, 'min_child_weight': 4, 'gamma': 0.8730267358591304, 'learning_rate': 0.15528140356916983, 'subsample': 0.8761467552297832, 'colsample_bytree': 0.9251811702996056, 'lambda': 0.009824519402661379, 'alpha': 0.02941586924125509, 'scale_pos_weight': 27.43449134728835}. Best is trial 3 with value: 3484.9134377472506.\n",
            "[I 2024-04-25 12:05:11,612] Trial 4 finished with value: 3489.7437851395157 and parameters: {'n_estimators': 689, 'max_depth': 7, 'min_child_weight': 2, 'gamma': 0.8607368155264256, 'learning_rate': 0.24116009795253524, 'subsample': 0.5582425615605799, 'colsample_bytree': 0.5120588242294946, 'lambda': 0.7740872850216043, 'alpha': 0.08654240969361797, 'scale_pos_weight': 86.30492591310282}. Best is trial 3 with value: 3484.9134377472506.\n",
            "[I 2024-04-25 12:21:17,015] Trial 5 finished with value: 3498.5933774212403 and parameters: {'n_estimators': 349, 'max_depth': 15, 'min_child_weight': 5, 'gamma': 0.5129160776002403, 'learning_rate': 0.19888980447054544, 'subsample': 0.5559388441780186, 'colsample_bytree': 0.5246031680429033, 'lambda': 0.11298695328857045, 'alpha': 0.17673355288981177, 'scale_pos_weight': 75.40925139524767}. Best is trial 3 with value: 3484.9134377472506.\n",
            "[I 2024-04-25 12:28:03,236] Trial 6 finished with value: 4703.496445898771 and parameters: {'n_estimators': 149, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.429313920585644, 'learning_rate': 0.14463373909929142, 'subsample': 0.692343462038563, 'colsample_bytree': 0.714447467809195, 'lambda': 8.177547199674631, 'alpha': 2.031733308405121, 'scale_pos_weight': 41.812007294648815}. Best is trial 3 with value: 3484.9134377472506.\n",
            "[I 2024-04-25 12:28:53,345] Trial 7 finished with value: 3469.606714807989 and parameters: {'n_estimators': 437, 'max_depth': 12, 'min_child_weight': 6, 'gamma': 0.3536940181543813, 'learning_rate': 0.23653331066818414, 'subsample': 0.9597762975896242, 'colsample_bytree': 0.7336078899341585, 'lambda': 0.002611332900967631, 'alpha': 0.0029932235464132013, 'scale_pos_weight': 10.57253123204403}. Best is trial 7 with value: 3469.606714807989.\n",
            "[I 2024-04-25 12:30:20,445] Trial 8 finished with value: 4073.172469199221 and parameters: {'n_estimators': 745, 'max_depth': 9, 'min_child_weight': 10, 'gamma': 0.11611033228599765, 'learning_rate': 0.031743715381035674, 'subsample': 0.5085543560247855, 'colsample_bytree': 0.7487798460882176, 'lambda': 0.150855890247408, 'alpha': 0.006807092702542598, 'scale_pos_weight': 11.751214673252154}. Best is trial 7 with value: 3469.606714807989.\n",
            "[I 2024-04-25 12:31:39,571] Trial 9 finished with value: 3519.788588505128 and parameters: {'n_estimators': 657, 'max_depth': 13, 'min_child_weight': 4, 'gamma': 0.655163629457184, 'learning_rate': 0.07133046128520851, 'subsample': 0.9961565778496315, 'colsample_bytree': 0.7161273455379915, 'lambda': 0.0014470262991201843, 'alpha': 0.0014263488440154262, 'scale_pos_weight': 3.128766299240623}. Best is trial 7 with value: 3469.606714807989.\n",
            "[I 2024-04-25 12:32:41,114] Trial 10 finished with value: 3462.611222638545 and parameters: {'n_estimators': 967, 'max_depth': 10, 'min_child_weight': 7, 'gamma': 0.017300051811736106, 'learning_rate': 0.2994628739488535, 'subsample': 0.9878351099092806, 'colsample_bytree': 0.8094638680964071, 'lambda': 0.004352678246169738, 'alpha': 0.0011336166731818543, 'scale_pos_weight': 36.70530771481664}. Best is trial 10 with value: 3462.611222638545.\n",
            "[I 2024-04-25 12:38:50,089] Trial 11 finished with value: 3458.9098166975778 and parameters: {'n_estimators': 996, 'max_depth': 10, 'min_child_weight': 7, 'gamma': 0.048642411439236644, 'learning_rate': 0.29837432228713884, 'subsample': 0.9898373156271857, 'colsample_bytree': 0.8350961180480424, 'lambda': 0.005369078483468314, 'alpha': 0.0010458991368176762, 'scale_pos_weight': 34.055589403357416}. Best is trial 11 with value: 3458.9098166975778.\n",
            "[I 2024-04-25 14:02:30,070] Trial 12 finished with value: 3468.7978110815925 and parameters: {'n_estimators': 978, 'max_depth': 9, 'min_child_weight': 8, 'gamma': 0.007362559191864793, 'learning_rate': 0.29109506443820854, 'subsample': 0.8516541674069503, 'colsample_bytree': 0.8343186297769347, 'lambda': 0.00613087287382778, 'alpha': 0.0011072946483969095, 'scale_pos_weight': 39.43572889754824}. Best is trial 11 with value: 3458.9098166975778.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros: {'n_estimators': 996, 'max_depth': 10, 'min_child_weight': 7, 'gamma': 0.048642411439236644, 'learning_rate': 0.29837432228713884, 'subsample': 0.9898373156271857, 'colsample_bytree': 0.8350961180480424, 'lambda': 0.005369078483468314, 'alpha': 0.0010458991368176762, 'scale_pos_weight': 34.055589403357416}\n",
            "Mejor RMSE obtenido: 3458.9098166975778\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0.0010458991368176762, base_score=None, booster=None,\n",
              "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.8350961180480424, device=None,\n",
              "             early_stopping_rounds=None, enable_categorical=False,\n",
              "             eval_metric=None, feature_types=None, gamma=0.048642411439236644,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, lambda=0.005369078483468314,\n",
              "             learning_rate=0.29837432228713884, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=996, n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0.0010458991368176762, base_score=None, booster=None,\n",
              "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.8350961180480424, device=None,\n",
              "             early_stopping_rounds=None, enable_categorical=False,\n",
              "             eval_metric=None, feature_types=None, gamma=0.048642411439236644,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, lambda=0.005369078483468314,\n",
              "             learning_rate=0.29837432228713884, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=996, n_jobs=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBRegressor(alpha=0.0010458991368176762, base_score=None, booster=None,\n",
              "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.8350961180480424, device=None,\n",
              "             early_stopping_rounds=None, enable_categorical=False,\n",
              "             eval_metric=None, feature_types=None, gamma=0.048642411439236644,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, lambda=0.005369078483468314,\n",
              "             learning_rate=0.29837432228713884, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=996, n_jobs=None, ...)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Función objetivo para la optimización\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 100)\n",
        "    }\n",
        "    \n",
        "    reg = XGBRegressor(**params, random_state=42)\n",
        "    reg.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n",
        "    \n",
        "    y_pred = reg.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    return rmse\n",
        "\n",
        "# Crear y ejecutar el estudio de optimización\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100, timeout=7200)  # 1 hora de límite\n",
        "\n",
        "# Resultados\n",
        "print(\"Mejores parámetros:\", study.best_params)\n",
        "print(\"Mejor RMSE obtenido:\", study.best_value)\n",
        "\n",
        "# Configuración del modelo con los mejores parámetros\n",
        "best_reg = XGBRegressor(**study.best_params, random_state=42)\n",
        "best_reg.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-25 14:19:27,759] A new study created in memory with name: no-name-46a70fa6-ba08-4939-9827-32c6c2a91fd1\n",
            "[I 2024-04-25 16:05:49,557] Trial 0 finished with value: 5997.567046217543 and parameters: {'rf_n_estimators': 389, 'rf_max_depth': 9, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 7, 'xgb_n_estimators': 392, 'xgb_max_depth': 6, 'xgb_min_child_weight': 10, 'xgb_gamma': 0.6549283630830555, 'xgb_learning_rate': 0.012454017827420245, 'xgb_subsample': 0.8076163019864833, 'xgb_colsample_bytree': 0.5004985904294686}. Best is trial 0 with value: 5997.567046217543.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros: {'rf_n_estimators': 389, 'rf_max_depth': 9, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 7, 'xgb_n_estimators': 392, 'xgb_max_depth': 6, 'xgb_min_child_weight': 10, 'xgb_gamma': 0.6549283630830555, 'xgb_learning_rate': 0.012454017827420245, 'xgb_subsample': 0.8076163019864833, 'xgb_colsample_bytree': 0.5004985904294686}\n",
            "Mejor RMSE obtenido: 5997.567046217543\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;rf&#x27;,\n",
              "                               RandomForestRegressor(max_depth=9,\n",
              "                                                     min_samples_leaf=7,\n",
              "                                                     min_samples_split=6,\n",
              "                                                     n_estimators=389,\n",
              "                                                     random_state=42)),\n",
              "                              (&#x27;xgb&#x27;,\n",
              "                               XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=0.5004985904294686,\n",
              "                                            device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=Fal...\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.012454017827420245,\n",
              "                                            max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=6,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=10, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=392, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=42, ...))],\n",
              "                  final_estimator=LinearRegression(), passthrough=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;rf&#x27;,\n",
              "                               RandomForestRegressor(max_depth=9,\n",
              "                                                     min_samples_leaf=7,\n",
              "                                                     min_samples_split=6,\n",
              "                                                     n_estimators=389,\n",
              "                                                     random_state=42)),\n",
              "                              (&#x27;xgb&#x27;,\n",
              "                               XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=0.5004985904294686,\n",
              "                                            device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=Fal...\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.012454017827420245,\n",
              "                                            max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=6,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=10, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=392, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=42, ...))],\n",
              "                  final_estimator=LinearRegression(), passthrough=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=9, min_samples_leaf=7, min_samples_split=6,\n",
              "                      n_estimators=389, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=0.5004985904294686, device=None,\n",
              "             early_stopping_rounds=None, enable_categorical=False,\n",
              "             eval_metric=None, feature_types=None, gamma=0.6549283630830555,\n",
              "             grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.012454017827420245,\n",
              "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=392, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "StackingRegressor(estimators=[('rf',\n",
              "                               RandomForestRegressor(max_depth=9,\n",
              "                                                     min_samples_leaf=7,\n",
              "                                                     min_samples_split=6,\n",
              "                                                     n_estimators=389,\n",
              "                                                     random_state=42)),\n",
              "                              ('xgb',\n",
              "                               XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=0.5004985904294686,\n",
              "                                            device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=Fal...\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.012454017827420245,\n",
              "                                            max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=6,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=10, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=392, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=42, ...))],\n",
              "                  final_estimator=LinearRegression(), passthrough=True)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Función objetivo para la optimización\n",
        "def objective(trial):\n",
        "    # Parámetros para Random Forest\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('rf_max_depth', 3, 20),\n",
        "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
        "    }\n",
        "    \n",
        "    # Parámetros para XGBoost\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('xgb_min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('xgb_gamma', 0.0, 1.0),\n",
        "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0)\n",
        "    }\n",
        "\n",
        "    # Crear los modelos base\n",
        "    rf = RandomForestRegressor(**rf_params, random_state=42)\n",
        "    xgb = XGBRegressor(**xgb_params, random_state=42)\n",
        "\n",
        "    # Crear el ensamble de stacking\n",
        "    stack_reg = StackingRegressor(\n",
        "        estimators=[('rf', rf), ('xgb', xgb)],\n",
        "        final_estimator=LinearRegression(),\n",
        "        passthrough=False\n",
        "    )\n",
        "    \n",
        "    # Entrenar el modelo de stacking\n",
        "    stack_reg.fit(X_train, y_train)\n",
        "    \n",
        "    # Hacer predicciones y calcular RMSE\n",
        "    y_pred = stack_reg.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    return rmse\n",
        "\n",
        "# Crear y ejecutar el estudio de optimización\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100, timeout=3600)  # 1 hora de límite\n",
        "\n",
        "# Resultados\n",
        "print(\"Mejores parámetros:\", study.best_trial.params)\n",
        "print(\"Mejor RMSE obtenido:\", study.best_trial.value)\n",
        "\n",
        "# Configurar el modelo con los mejores parámetros\n",
        "rf_best = RandomForestRegressor(**{k[3:]: v for k, v in study.best_params.items() if k.startswith('rf_')}, random_state=42)\n",
        "xgb_best = XGBRegressor(**{k[4:]: v for k, v in study.best_params.items() if k.startswith('xgb_')}, random_state=42)\n",
        "stack_reg_best = StackingRegressor(\n",
        "    estimators=[('rf', rf_best), ('xgb', xgb_best)],\n",
        "    final_estimator=LinearRegression(),\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "# Entrenar el modelo final\n",
        "stack_reg_best.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-26 00:35:47,494] A new study created in memory with name: no-name-8c8e7b7f-0527-48b9-aafa-b618b480340a\n",
            "[I 2024-04-26 00:36:52,785] Trial 0 finished with value: 3578.2688753983525 and parameters: {'n_estimators': 615, 'max_depth': 10, 'min_child_weight': 3, 'gamma': 0.1519025210338012, 'learning_rate': 0.24665056488928921, 'subsample': 0.6433745179036909, 'colsample_bytree': 0.6242354505683942, 'lambda': 0.07041188874749668, 'alpha': 3.4568441069804634, 'scale_pos_weight': 95.15152827843455}. Best is trial 0 with value: 3578.2688753983525.\n",
            "[I 2024-04-26 00:37:12,611] Trial 1 finished with value: 4182.837443299656 and parameters: {'n_estimators': 116, 'max_depth': 6, 'min_child_weight': 1, 'gamma': 0.03504795172814512, 'learning_rate': 0.29783498105540446, 'subsample': 0.8296440087760606, 'colsample_bytree': 0.8296347562054345, 'lambda': 0.4106009982636856, 'alpha': 0.024618634368798357, 'scale_pos_weight': 56.32348767128386}. Best is trial 0 with value: 3578.2688753983525.\n",
            "[I 2024-04-26 00:38:56,909] Trial 2 finished with value: 3595.4015415331546 and parameters: {'n_estimators': 924, 'max_depth': 13, 'min_child_weight': 7, 'gamma': 0.011928666065796345, 'learning_rate': 0.041492636762209205, 'subsample': 0.6851253710365288, 'colsample_bytree': 0.7415250435092761, 'lambda': 4.58635835490924, 'alpha': 0.007495618150413531, 'scale_pos_weight': 12.333974834296942}. Best is trial 0 with value: 3578.2688753983525.\n",
            "[I 2024-04-26 00:40:18,729] Trial 3 finished with value: 3671.2354476263004 and parameters: {'n_estimators': 917, 'max_depth': 6, 'min_child_weight': 9, 'gamma': 0.38740549664196466, 'learning_rate': 0.08994837146019898, 'subsample': 0.9027918849583745, 'colsample_bytree': 0.6867788950730546, 'lambda': 0.029225018125007045, 'alpha': 0.04234043984714231, 'scale_pos_weight': 49.43611846097513}. Best is trial 0 with value: 3578.2688753983525.\n",
            "[I 2024-04-26 00:41:43,326] Trial 4 finished with value: 3572.6521780363637 and parameters: {'n_estimators': 824, 'max_depth': 9, 'min_child_weight': 1, 'gamma': 0.657380839120231, 'learning_rate': 0.24941087304908785, 'subsample': 0.9214440765449963, 'colsample_bytree': 0.5612689505081903, 'lambda': 0.05137593314131385, 'alpha': 0.011148732607144676, 'scale_pos_weight': 29.946631499377055}. Best is trial 4 with value: 3572.6521780363637.\n",
            "[I 2024-04-26 00:42:39,264] Trial 5 finished with value: 4496.235111641224 and parameters: {'n_estimators': 361, 'max_depth': 13, 'min_child_weight': 2, 'gamma': 0.6659483555630895, 'learning_rate': 0.02476543826669056, 'subsample': 0.7739278298956351, 'colsample_bytree': 0.9537966003799705, 'lambda': 1.954411976379256, 'alpha': 0.8324907757302512, 'scale_pos_weight': 46.0427523967782}. Best is trial 4 with value: 3572.6521780363637.\n",
            "[I 2024-04-26 00:44:08,103] Trial 6 finished with value: 3759.0886487411667 and parameters: {'n_estimators': 700, 'max_depth': 14, 'min_child_weight': 4, 'gamma': 0.19967756053923136, 'learning_rate': 0.22541564750039636, 'subsample': 0.7990081311953334, 'colsample_bytree': 0.884304807883417, 'lambda': 0.04891275632477054, 'alpha': 1.8757218422577595, 'scale_pos_weight': 64.54476622767594}. Best is trial 4 with value: 3572.6521780363637.\n",
            "[I 2024-04-26 00:45:21,773] Trial 7 finished with value: 3642.5701241213133 and parameters: {'n_estimators': 569, 'max_depth': 14, 'min_child_weight': 3, 'gamma': 0.18247213692055808, 'learning_rate': 0.05128383388251003, 'subsample': 0.9563312773328867, 'colsample_bytree': 0.6312102961151155, 'lambda': 0.0019904465219427563, 'alpha': 0.13515452187975027, 'scale_pos_weight': 50.915572200754916}. Best is trial 4 with value: 3572.6521780363637.\n",
            "[I 2024-04-26 00:46:17,122] Trial 8 finished with value: 3503.3237530144015 and parameters: {'n_estimators': 481, 'max_depth': 10, 'min_child_weight': 8, 'gamma': 0.8201963159365868, 'learning_rate': 0.21431954818347557, 'subsample': 0.5390391158758403, 'colsample_bytree': 0.8554839973564105, 'lambda': 2.882179072277013, 'alpha': 0.0018067772146681865, 'scale_pos_weight': 33.609371202398336}. Best is trial 8 with value: 3503.3237530144015.\n",
            "[I 2024-04-26 00:47:44,566] Trial 9 finished with value: 3520.7976568258564 and parameters: {'n_estimators': 715, 'max_depth': 13, 'min_child_weight': 5, 'gamma': 0.31203357857329805, 'learning_rate': 0.06750391253548003, 'subsample': 0.5794327269770463, 'colsample_bytree': 0.994921196325395, 'lambda': 0.017293541001454738, 'alpha': 0.0023303567859099335, 'scale_pos_weight': 20.23702476633427}. Best is trial 8 with value: 3503.3237530144015.\n",
            "[I 2024-04-26 00:48:21,189] Trial 10 finished with value: 4802.099443116349 and parameters: {'n_estimators': 317, 'max_depth': 3, 'min_child_weight': 10, 'gamma': 0.967135154749209, 'learning_rate': 0.14939637435775643, 'subsample': 0.5099247548016879, 'colsample_bytree': 0.825215568962554, 'lambda': 0.720413796271311, 'alpha': 0.0011554360047707278, 'scale_pos_weight': 1.9847479252438802}. Best is trial 8 with value: 3503.3237530144015.\n",
            "[I 2024-04-26 00:49:11,986] Trial 11 finished with value: 3529.722225754577 and parameters: {'n_estimators': 422, 'max_depth': 10, 'min_child_weight': 6, 'gamma': 0.998928377079139, 'learning_rate': 0.15290278561454917, 'subsample': 0.5317246711336141, 'colsample_bytree': 0.985223775206459, 'lambda': 0.005051613150295499, 'alpha': 0.001118062004890552, 'scale_pos_weight': 24.186125672681253}. Best is trial 8 with value: 3503.3237530144015.\n",
            "[I 2024-04-26 00:50:37,940] Trial 12 finished with value: 3492.438061083131 and parameters: {'n_estimators': 734, 'max_depth': 11, 'min_child_weight': 8, 'gamma': 0.46490659531072265, 'learning_rate': 0.11553990862038926, 'subsample': 0.6016788620591338, 'colsample_bytree': 0.8968812726623809, 'lambda': 0.004873466232482512, 'alpha': 0.003462214441809711, 'scale_pos_weight': 28.299238121920812}. Best is trial 12 with value: 3492.438061083131.\n",
            "[I 2024-04-26 00:51:34,160] Trial 13 finished with value: 3639.6665942202712 and parameters: {'n_estimators': 507, 'max_depth': 8, 'min_child_weight': 8, 'gamma': 0.615714609349186, 'learning_rate': 0.11347124752596467, 'subsample': 0.6163479590861286, 'colsample_bytree': 0.8790622874621055, 'lambda': 0.2565104166333607, 'alpha': 0.005100033738051999, 'scale_pos_weight': 33.57947767837089}. Best is trial 12 with value: 3492.438061083131.\n",
            "[I 2024-04-26 00:52:09,925] Trial 14 finished with value: 3571.9708492243044 and parameters: {'n_estimators': 261, 'max_depth': 11, 'min_child_weight': 8, 'gamma': 0.5029177624136028, 'learning_rate': 0.2168774417327739, 'subsample': 0.6895468835040366, 'colsample_bytree': 0.7700039555006764, 'lambda': 9.25014004058713, 'alpha': 0.19363619855674838, 'scale_pos_weight': 81.98400151925888}. Best is trial 12 with value: 3492.438061083131.\n",
            "[I 2024-04-26 00:53:26,385] Trial 15 finished with value: 3491.866011597731 and parameters: {'n_estimators': 779, 'max_depth': 7, 'min_child_weight': 10, 'gamma': 0.8225799541872404, 'learning_rate': 0.1865144623971005, 'subsample': 0.5765963454254389, 'colsample_bytree': 0.9175541132167292, 'lambda': 0.007930947541170524, 'alpha': 0.026826708351221477, 'scale_pos_weight': 38.214406981422385}. Best is trial 15 with value: 3491.866011597731.\n",
            "[I 2024-04-26 00:54:43,722] Trial 16 finished with value: 3485.686634430714 and parameters: {'n_estimators': 790, 'max_depth': 7, 'min_child_weight': 10, 'gamma': 0.8203091299737871, 'learning_rate': 0.18079237462385642, 'subsample': 0.7177880471967579, 'colsample_bytree': 0.9256111263111041, 'lambda': 0.0010058432225847434, 'alpha': 0.035104801504273385, 'scale_pos_weight': 68.29464905219683}. Best is trial 16 with value: 3485.686634430714.\n",
            "[I 2024-04-26 00:56:02,744] Trial 17 finished with value: 3492.3148438046537 and parameters: {'n_estimators': 838, 'max_depth': 6, 'min_child_weight': 10, 'gamma': 0.8445615381630862, 'learning_rate': 0.18236079332425914, 'subsample': 0.7198553769803938, 'colsample_bytree': 0.9209940962383344, 'lambda': 0.001042506590748133, 'alpha': 0.39469077394186736, 'scale_pos_weight': 69.06287375868467}. Best is trial 16 with value: 3485.686634430714.\n",
            "[I 2024-04-26 00:57:27,295] Trial 18 finished with value: 3590.1055111659393 and parameters: {'n_estimators': 961, 'max_depth': 4, 'min_child_weight': 10, 'gamma': 0.7950913869863112, 'learning_rate': 0.1832640520215159, 'subsample': 0.8482794243754579, 'colsample_bytree': 0.7521941672108069, 'lambda': 0.0070987053225720015, 'alpha': 0.04554305778256451, 'scale_pos_weight': 76.19232106084593}. Best is trial 16 with value: 3485.686634430714.\n",
            "[I 2024-04-26 00:58:46,128] Trial 19 finished with value: 3482.2145752179363 and parameters: {'n_estimators': 811, 'max_depth': 7, 'min_child_weight': 9, 'gamma': 0.8960748136102593, 'learning_rate': 0.179260984876997, 'subsample': 0.7296553927855958, 'colsample_bytree': 0.787177548783876, 'lambda': 0.001845536845585839, 'alpha': 0.030826821732361315, 'scale_pos_weight': 42.66826142640955}. Best is trial 19 with value: 3482.2145752179363.\n",
            "[I 2024-04-26 00:59:44,724] Trial 20 finished with value: 3615.343768234079 and parameters: {'n_estimators': 627, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 0.9148334542254195, 'learning_rate': 0.28698580693385645, 'subsample': 0.7309491900242472, 'colsample_bytree': 0.5114025219316634, 'lambda': 0.0010911985219089358, 'alpha': 0.07791289502507058, 'scale_pos_weight': 87.47488973691723}. Best is trial 19 with value: 3482.2145752179363.\n",
            "[I 2024-04-26 01:01:05,834] Trial 21 finished with value: 3484.209127750979 and parameters: {'n_estimators': 824, 'max_depth': 7, 'min_child_weight': 9, 'gamma': 0.7573598366095513, 'learning_rate': 0.18400649680826195, 'subsample': 0.6637017502330157, 'colsample_bytree': 0.9393495281139435, 'lambda': 0.012000903851882919, 'alpha': 0.01665908805476359, 'scale_pos_weight': 41.24238375418379}. Best is trial 19 with value: 3482.2145752179363.\n",
            "[I 2024-04-26 01:02:45,515] Trial 22 finished with value: 3474.0597754176706 and parameters: {'n_estimators': 997, 'max_depth': 8, 'min_child_weight': 9, 'gamma': 0.7689185713832303, 'learning_rate': 0.1275200291319346, 'subsample': 0.6605300653530946, 'colsample_bytree': 0.7909903552588888, 'lambda': 0.0026286687254294676, 'alpha': 0.01774933247693236, 'scale_pos_weight': 61.44918964552461}. Best is trial 22 with value: 3474.0597754176706.\n",
            "[I 2024-04-26 01:04:22,053] Trial 23 finished with value: 3475.13171219684 and parameters: {'n_estimators': 993, 'max_depth': 8, 'min_child_weight': 9, 'gamma': 0.7187591735474891, 'learning_rate': 0.12402493237533355, 'subsample': 0.6596795436067145, 'colsample_bytree': 0.800667999936141, 'lambda': 0.003461565351358504, 'alpha': 0.00951167430476656, 'scale_pos_weight': 42.1201502982785}. Best is trial 22 with value: 3474.0597754176706.\n",
            "[I 2024-04-26 01:06:13,125] Trial 24 finished with value: 3472.8463149029208 and parameters: {'n_estimators': 998, 'max_depth': 8, 'min_child_weight': 7, 'gamma': 0.6967843622797218, 'learning_rate': 0.1285277523219418, 'subsample': 0.7714207027433634, 'colsample_bytree': 0.7842871398614083, 'lambda': 0.002817181447495947, 'alpha': 0.009909485249160336, 'scale_pos_weight': 59.421958711172515}. Best is trial 24 with value: 3472.8463149029208.\n",
            "[I 2024-04-26 01:08:06,136] Trial 25 finished with value: 3471.4052589010776 and parameters: {'n_estimators': 993, 'max_depth': 9, 'min_child_weight': 7, 'gamma': 0.7173556504612306, 'learning_rate': 0.12243997984055971, 'subsample': 0.7785809748368766, 'colsample_bytree': 0.7226177296126691, 'lambda': 0.002959277805602549, 'alpha': 0.008194286616522058, 'scale_pos_weight': 57.30600923378645}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:09:50,680] Trial 26 finished with value: 3513.7947167678035 and parameters: {'n_estimators': 903, 'max_depth': 9, 'min_child_weight': 7, 'gamma': 0.5738739264708472, 'learning_rate': 0.08569847079829336, 'subsample': 0.7814604914962529, 'colsample_bytree': 0.706896312553186, 'lambda': 0.0026595375919799932, 'alpha': 0.00494513261601239, 'scale_pos_weight': 59.21393512994799}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:11:46,323] Trial 27 finished with value: 3492.9353368627962 and parameters: {'n_estimators': 991, 'max_depth': 11, 'min_child_weight': 7, 'gamma': 0.7035521989913728, 'learning_rate': 0.13386206699233733, 'subsample': 0.8703851565633639, 'colsample_bytree': 0.6737188245462367, 'lambda': 0.012432845409803496, 'alpha': 8.551424810810438, 'scale_pos_weight': 75.29451868116546}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:13:19,113] Trial 28 finished with value: 3566.0804379817673 and parameters: {'n_estimators': 875, 'max_depth': 8, 'min_child_weight': 5, 'gamma': 0.5400197528402586, 'learning_rate': 0.0841988109155761, 'subsample': 0.826875514807548, 'colsample_bytree': 0.7203014822630234, 'lambda': 0.022665583103168938, 'alpha': 0.012537892322134921, 'scale_pos_weight': 58.52996710515386}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:15:02,609] Trial 29 finished with value: 3481.01274226491 and parameters: {'n_estimators': 943, 'max_depth': 9, 'min_child_weight': 6, 'gamma': 0.6056833884496888, 'learning_rate': 0.10218741717643903, 'subsample': 0.770305123025971, 'colsample_bytree': 0.6641721475099287, 'lambda': 0.10420010842836817, 'alpha': 0.07856696864991604, 'scale_pos_weight': 95.33305017126345}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:16:07,073] Trial 30 finished with value: 3728.9804005474216 and parameters: {'n_estimators': 622, 'max_depth': 5, 'min_child_weight': 7, 'gamma': 0.43842292435779207, 'learning_rate': 0.14577044959944413, 'subsample': 0.6329534573376201, 'colsample_bytree': 0.6164912812561734, 'lambda': 0.0034705286930764045, 'alpha': 0.003057356882799744, 'scale_pos_weight': 87.15019611571162}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:17:50,356] Trial 31 finished with value: 3480.242714708513 and parameters: {'n_estimators': 980, 'max_depth': 8, 'min_child_weight': 9, 'gamma': 0.7304685021125009, 'learning_rate': 0.1267069188986594, 'subsample': 0.6461324368655389, 'colsample_bytree': 0.7959308445364267, 'lambda': 0.0024988700633265196, 'alpha': 0.00777670649035249, 'scale_pos_weight': 54.11750932361036}. Best is trial 25 with value: 3471.4052589010776.\n",
            "[I 2024-04-26 01:19:34,069] Trial 32 finished with value: 3469.968206330262 and parameters: {'n_estimators': 999, 'max_depth': 8, 'min_child_weight': 8, 'gamma': 0.7143690834562483, 'learning_rate': 0.1300243979095427, 'subsample': 0.8182173905394724, 'colsample_bytree': 0.8217946044539075, 'lambda': 0.00443280199125384, 'alpha': 0.017852606337747958, 'scale_pos_weight': 64.46052153382485}. Best is trial 32 with value: 3469.968206330262.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
            "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
            "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
            "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Función objetivo para la optimización\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 100)\n",
        "    }\n",
        "    \n",
        "    reg = XGBRegressor(**params, random_state=42)\n",
        "    \n",
        "    # Crear un scorer RMSE negativo, ya que por defecto mayor es mejor\n",
        "    rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    \n",
        "    # Calcula el RMSE promedio en los 3 folds\n",
        "    scores = cross_val_score(reg, data, target, cv=kf, scoring=rmse_scorer)\n",
        "    rmse_mean = -scores.mean()  # Negar el promedio para obtener RMSE positivo\n",
        "    return rmse_mean\n",
        "\n",
        "# Crear y ejecutar el estudio de optimización\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100, timeout=7200)  # 2 horas de límite\n",
        "\n",
        "# Resultados\n",
        "print(\"Mejores parámetros:\", study.best_params)\n",
        "print(\"Mejor RMSE obtenido:\", study.best_value)\n",
        "\n",
        "# Configuración del modelo con los mejores parámetros\n",
        "best_reg = XGBRegressor(**study.best_params, random_state=42)\n",
        "best_reg.fit(data, target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "g7J8SxNkiWz8",
        "outputId": "0f589011-b729-4496-a074-d3d53c2a140e"
      },
      "outputs": [],
      "source": [
        "# Modelo sin calibrar\n",
        "xgb_1 = XGBRegressor(random_state=42)\n",
        "xgb_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxvytrwVip7w",
        "outputId": "2f4d25bd-c933-4c64-8279-c2881552c680"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento y desempeño del modelo XGBRegressor\n",
        "xgb_1.fit(X_train, y_train)\n",
        "y_pred = xgb_1.predict(X_test)\n",
        "# Calculo del MSE y el MAE\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"El modelo XGBRegressor tiene un RMSE igual a \" +str(rmse)+ \" y un MAE igual a \"+str(mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqU7V7HIgn-z",
        "outputId": "cf0cda62-ca39-45c9-8f32-6f6de0a5d6dc"
      },
      "outputs": [],
      "source": [
        "# pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0dDtGC8h6Eq"
      },
      "source": [
        "## Prueba 1\n",
        "Fuente: https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_calibrado = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.0006300622095494117,\n",
        "    alpha=0.00014622406232897364,\n",
        "    subsample=0.23255033200475195,\n",
        "    colsample_bytree=0.4885554959213272,\n",
        "    max_depth=9,\n",
        "    min_child_weight=8,\n",
        "    eta=0.7114903492018297,\n",
        "    gamma=6.252368056908203e-05,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_calibrado.fit(X_train, y_train)\n",
        "y_pred = xgb_calibrado.predict(X_test)\n",
        "mse_xgb_calibrado = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_calibrado = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_calibrado = np.sqrt(mse_xgb_calibrado)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_calibrado)+ \" y un MAE igual a \"+str(mae_xgb_calibrado))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Intento #2 agregando más ensayos\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_cal = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=1.3618109137815986e-08,\n",
        "    alpha=0.0068473212560469085,\n",
        "    subsample=0.5383447526406704,\n",
        "    colsample_bytree=0.7375702235448874,\n",
        "    max_depth=9,\n",
        "    min_child_weight=4,\n",
        "    eta=0.925350157501082,\n",
        "    gamma=0.8591307262185451,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_cal.fit(X_train, y_train)\n",
        "y_pred = xgb_cal.predict(X_test)\n",
        "mse_xgb_cal = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_cal = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_cal = np.sqrt(mse_xgb_cal)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_cal)+ \" y un MAE igual a \"+str(mae_xgb_cal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# intento # 3, agregando el parámetro n_estimators\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "        # número de árboles en el ensamble\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_cal_2 = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.9501091374676599,\n",
        "    alpha=2.2458201898736107e-06,\n",
        "    subsample=0.33554148719968135,\n",
        "    colsample_bytree=0.6131209517619073,\n",
        "    n_estimators= 988,\n",
        "    max_depth=3,\n",
        "    min_child_weight=8,\n",
        "    eta=0.9710181349940284,\n",
        "    gamma=0.0031652899319421076,\n",
        "    grow_policy='depthwise',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_cal_2.fit(X_train, y_train)\n",
        "y_pred = xgb_cal_2.predict(X_test)\n",
        "mse_xgb_cal_2 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_cal_2 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_cal_2 = np.sqrt(mse_xgb_cal_2)\n",
        "print(\"El modelo XGB calibrado usando Optuna tiene un RMSE igual a \" +str(rmse_xgb_cal_2)+ \" y un MAE igual a \"+str(mae_xgb_cal_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Intento #4 cambiando los valores del parámetro gamma\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "        # número de árboles en el ensamble\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 500, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_2 = XGBRegressor(\n",
        "    reg_lambda=9.564561673448604e-07,\n",
        "    alpha=1.6980413730845048e-05,\n",
        "    subsample=0.2288913151339783,\n",
        "    colsample_bytree=0.9932758875637113,\n",
        "    n_estimators= 699,\n",
        "    max_depth=9,\n",
        "    min_child_weight=5,\n",
        "    eta=0.9676347877899362,\n",
        "    gamma=1.115418460534174e-08,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_2.fit(X_train, y_train)\n",
        "y_pred = xgb_2.predict(X_test)\n",
        "mse_xgb_2 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_2 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_2 = np.sqrt(mse_xgb_2)\n",
        "print(\"El modelo XGB calibrado usando Optuna tiene un RMSE igual a \" +str(rmse_xgb_2)+ \" y un MAE igual a \"+str(mae_xgb_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "# Calibración de gamma\n",
        "gamma = np.arange(0, 100, 10 )\n",
        "MSE_2 = []\n",
        "for valor in gamma:\n",
        "    xgb = XGBRegressor(gamma=valor, random_state=1)\n",
        "    MSE_2.append(cross_val_score(xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
        "    MSE_2 = [abs(valor) for valor in MSE_2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(gamma, MSE_2)\n",
        "plt.title(\"Desempeño de XGBoost por cada valor de gamma\")\n",
        "plt.xlabel('gamma')\n",
        "plt.ylabel('MSE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cargar predicciones en Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuaaUkJnXQWU",
        "outputId": "059224b3-14e9-479a-b522-fc0cbb689d44"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJknYwT_XQWV",
        "outputId": "1428c820-2146-481a-b6a9-aad3d5bdcc41"
      },
      "outputs": [],
      "source": [
        "X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GH273Up_XQWd"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas en df_test\n",
        "df_test_ = pd.get_dummies(df_test, columns=categorical_columns).astype(int)\n",
        "\n",
        "# Alinear las columnas de df_test con X_train\n",
        "df_test_aligned, _ = df_test_.align(X_train, axis=1, fill_value=0)\n",
        "\n",
        "column_order = X_train.columns.tolist()\n",
        "\n",
        "# Reordenar las columnas de df_test_aligned de acuerdo con el orden en X_train\n",
        "df_test_ordenado = df_test_aligned[column_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sR6rRk4vXQWe",
        "outputId": "ecc6eb21-29f7-4694-fd91-2b476265db41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Mileage', 'State_ AK', 'State_ AL', 'State_ AR', 'State_ AZ',\n",
              "       'State_ CA', 'State_ CO', 'State_ CT', 'State_ DC',\n",
              "       ...\n",
              "       'Model_Yaris4dr', 'Model_YarisBase', 'Model_YarisLE', 'Model_Yukon',\n",
              "       'Model_Yukon2WD', 'Model_Yukon4WD', 'Model_Yukon4dr', 'Model_tC2dr',\n",
              "       'Model_xB5dr', 'Model_xD5dr'],\n",
              "      dtype='object', length=616)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test_ordenado.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4usiAcIJXQWg",
        "outputId": "f23f280f-6cae-4d60-bd89-10708ed029b5"
      },
      "outputs": [],
      "source": [
        "# El modelo montado en Kaggle fue:\n",
        "xgb_calibrado_3 = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.30212357583678445,\n",
        "    alpha=0.18211410327397226,\n",
        "    subsample=0.3521449713976327,\n",
        "    colsample_bytree=0.44811953613366806,\n",
        "    max_depth=9,\n",
        "    min_child_weight=9,\n",
        "    eta=0.8918833748094722,\n",
        "    gamma=0.00034064735565798957,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1  # Si deseas mantener una semilla aleatoria fija\n",
        ")\n",
        "xgb_calibrado_3.fit(X_train, y_train)\n",
        "y_pred = xgb_calibrado_3.predict(X_test)\n",
        "mse_xgb_calibrado_3 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_calibrado_3 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_calibrado_3 = np.sqrt(mse_xgb_calibrado_3)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_calibrado_3)+ \" y un MAE igual a \"+str(mae_xgb_calibrado_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se usa df_test_aligned para predecir\n",
        "y_pred = best_reg.predict(df_test_ordenado)\n",
        "\n",
        "predictions_df = pd.DataFrame(y_pred, index=df_test_ordenado.index, columns=['Price'])\n",
        "\n",
        "predictions_df.to_csv('predicciones_2.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
