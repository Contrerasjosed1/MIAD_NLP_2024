{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdcRb56bDKlX"
      },
      "source": [
        "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NTzkK7UDKle"
      },
      "source": [
        "# Proyecto 1 - Predicción de precios de vehículos usados\n",
        "\n",
        "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desarrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
        "\n",
        "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
        "\n",
        "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/competitions/miad2024-12-prediccion-precio-vehiculos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMjkssSaDKlh"
      },
      "source": [
        "# Procesamiento y exploración preliminar de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mAyLUrhTDKlj"
      },
      "outputs": [],
      "source": [
        "# librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6XkvrmVuDKlm"
      },
      "outputs": [],
      "source": [
        "# cargar datos (se tiene en .csv en local)\n",
        "df_train=pd.read_csv(\"dataTrain_carListings.csv\")\n",
        "# data test tiene una columna llamada ID, que solamente es el orden de numeros\n",
        "df_test=pd.read_csv(\"dataTest_carListings.csv\", index_col=0)\n",
        "# Cargar datos reales\n",
        "# df_real=pd.read_csv(\"true_car_listings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk8Fj1gdDKlw",
        "outputId": "9437b007-7093-475b-ba3e-a3182c43aa22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Price', 'Year', 'Mileage', 'State', 'Make', 'Model'], dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# eliminar columnas adicionales\n",
        "# df_real.drop([\"City\", \"Vin\"], axis=1, inplace=True)\n",
        "# df_real.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhcgCw7ctyX"
      },
      "source": [
        "## Entrenamiento y calibración de XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhcUcqfQXQWI",
        "outputId": "479d7db4-079f-4d7a-a05a-040e9afac283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\wendy\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\wendy\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DSRUgNBrieMx"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-w1SeBtj8DV",
        "outputId": "97249971-400c-4d0d-b00f-4b39934272ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400000 entries, 0 to 399999\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Price    400000 non-null  int64 \n",
            " 1   Year     400000 non-null  int64 \n",
            " 2   Mileage  400000 non-null  int64 \n",
            " 3   State    400000 non-null  object\n",
            " 4   Make     400000 non-null  object\n",
            " 5   Model    400000 non-null  object\n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 18.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nA7XBgKCj7Gz"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas\n",
        "categorical_columns = ['State', 'Make', 'Model']\n",
        "df_train = pd.get_dummies(df_train, columns=categorical_columns).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLdHctdRXQWL",
        "outputId": "6a18d770-6b7d-45eb-9054-7a5d4088c5c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de X_train: <class 'pandas.core.frame.DataFrame'>\n",
            "Tipo de X_test: <class 'pandas.core.frame.DataFrame'>\n",
            "Tipo de y_train: <class 'pandas.core.series.Series'>\n",
            "Tipo de y_test: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = df_train.drop(['Price'], axis=1)\n",
        "target = df_train['Price']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convertir los arrays resultantes en DataFrames de pandas\n",
        "X_train = pd.DataFrame(X_train, columns=data.columns)\n",
        "X_test = pd.DataFrame(X_test, columns=data.columns)\n",
        "y_train = pd.Series(y_train, name='Price')\n",
        "y_test = pd.Series(y_test, name='Price')\n",
        "\n",
        "# Verifica los tipos de datos de las estructuras resultantes\n",
        "print(\"Tipo de X_train:\", type(X_train))\n",
        "print(\"Tipo de X_test:\", type(X_test))\n",
        "print(\"Tipo de y_train:\", type(y_train))\n",
        "print(\"Tipo de y_test:\", type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "g7J8SxNkiWz8",
        "outputId": "0f589011-b729-4496-a074-d3d53c2a140e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Modelo sin calibrar\n",
        "xgb_1 = XGBRegressor(random_state=42)\n",
        "xgb_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxvytrwVip7w",
        "outputId": "2f4d25bd-c933-4c64-8279-c2881552c680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGBRegressor tiene un RMSE igual a 4266.196601029799 y un MAE igual a 3039.4960325634765\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento y desempeño del modelo XGBRegressor\n",
        "xgb_1.fit(X_train, y_train)\n",
        "y_pred = xgb_1.predict(X_test)\n",
        "# Calculo del MSE y el MAE\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"El modelo XGBRegressor tiene un RMSE igual a \" +str(rmse)+ \" y un MAE igual a \"+str(mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqU7V7HIgn-z",
        "outputId": "cf0cda62-ca39-45c9-8f32-6f6de0a5d6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (2.0.25)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0dDtGC8h6Eq"
      },
      "source": [
        "## Prueba 1\n",
        "Fuente: https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 12:20:30,828] A new study created in memory with name: no-name-33eca8ba-9df3-489a-90dc-011d51e34950\n",
            "[I 2024-04-21 12:24:49,453] Trial 0 finished with value: 37925401.11891 and parameters: {'lambda': 0.2377924860828489, 'alpha': 1.1928210388948983e-06, 'subsample': 0.517887910998116, 'colsample_bytree': 0.37144314887294033, 'max_depth': 9, 'min_child_weight': 4, 'eta': 0.4424348924249991, 'gamma': 0.07010736549875739, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 37925401.11891.\n",
            "[I 2024-04-21 12:28:14,563] Trial 1 finished with value: 115477217.75042 and parameters: {'lambda': 3.3370263451803966e-05, 'alpha': 0.0023660342486206427, 'subsample': 0.5043220547062435, 'colsample_bytree': 0.600236878839564, 'max_depth': 9, 'min_child_weight': 8, 'eta': 3.104995561287136e-07, 'gamma': 0.05226933430037451, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 37925401.11891.\n",
            "[I 2024-04-21 12:31:27,114] Trial 2 finished with value: 40165208.81444 and parameters: {'lambda': 2.3574874341341094e-05, 'alpha': 1.3310223317464752e-08, 'subsample': 0.8632565060485334, 'colsample_bytree': 0.9840772987363333, 'max_depth': 5, 'min_child_weight': 6, 'eta': 0.6430186258789877, 'gamma': 7.967326572347691e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 37925401.11891.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  3\n",
            "Best trial:\n",
            "  Value: 37925401.11891\n",
            "  Params: \n",
            "    lambda: 0.2377924860828489\n",
            "    alpha: 1.1928210388948983e-06\n",
            "    subsample: 0.517887910998116\n",
            "    colsample_bytree: 0.37144314887294033\n",
            "    max_depth: 9\n",
            "    min_child_weight: 4\n",
            "    eta: 0.4424348924249991\n",
            "    gamma: 0.07010736549875739\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a 3814.2775905936596 y un MAE igual a 2524.4249530563734\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_calibrado = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.0006300622095494117,\n",
        "    alpha=0.00014622406232897364,\n",
        "    subsample=0.23255033200475195,\n",
        "    colsample_bytree=0.4885554959213272,\n",
        "    max_depth=9,\n",
        "    min_child_weight=8,\n",
        "    eta=0.7114903492018297,\n",
        "    gamma=6.252368056908203e-05,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_calibrado.fit(X_train, y_train)\n",
        "y_pred = xgb_calibrado.predict(X_test)\n",
        "mse_xgb_calibrado = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_calibrado = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_calibrado = np.sqrt(mse_xgb_calibrado)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_calibrado)+ \" y un MAE igual a \"+str(mae_xgb_calibrado))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 12:31:32,436] A new study created in memory with name: no-name-82da397a-87c5-4c63-8bf0-a96a089c94a3\n",
            "[I 2024-04-21 12:34:26,640] Trial 0 finished with value: 115157053.90523 and parameters: {'lambda': 0.003821045178997646, 'alpha': 4.6153819347255276e-05, 'subsample': 0.6885969782823933, 'colsample_bytree': 0.2416612299893023, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0008791976332645826, 'gamma': 5.450329820320646e-07, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 115157053.90523.\n",
            "[I 2024-04-21 12:37:57,135] Trial 1 finished with value: 105737286.76907 and parameters: {'lambda': 0.011166730434234362, 'alpha': 0.037878457109529695, 'subsample': 0.2272940763931083, 'colsample_bytree': 0.3956114672299532, 'max_depth': 3, 'min_child_weight': 2, 'eta': 0.028213157813213378, 'gamma': 0.00016075556493695383, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 105737286.76907.\n",
            "[I 2024-04-21 12:40:59,454] Trial 2 finished with value: 111473270.00924 and parameters: {'lambda': 0.22986921745615574, 'alpha': 2.201385457746818e-08, 'subsample': 0.24121839377271767, 'colsample_bytree': 0.50358597280775, 'max_depth': 5, 'min_child_weight': 10, 'eta': 0.006998716247270864, 'gamma': 4.0683165161073765e-05, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 105737286.76907.\n",
            "[I 2024-04-21 12:42:55,943] Trial 3 finished with value: 72818784.22598 and parameters: {'lambda': 0.0004316299082724523, 'alpha': 0.6267954247904204, 'subsample': 0.8838090182315328, 'colsample_bytree': 0.5519289342356889, 'max_depth': 7, 'min_child_weight': 6, 'eta': 0.0952435381470123, 'gamma': 0.00010237601066799779, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 72818784.22598.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  4\n",
            "Best trial:\n",
            "  Value: 72818784.22598\n",
            "  Params: \n",
            "    lambda: 0.0004316299082724523\n",
            "    alpha: 0.6267954247904204\n",
            "    subsample: 0.8838090182315328\n",
            "    colsample_bytree: 0.5519289342356889\n",
            "    max_depth: 7\n",
            "    min_child_weight: 6\n",
            "    eta: 0.0952435381470123\n",
            "    gamma: 0.00010237601066799779\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "# Intento #2 agregando más ensayos\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a 3835.3596453796845 y un MAE igual a 2457.922469499817\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_cal = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=1.3618109137815986e-08,\n",
        "    alpha=0.0068473212560469085,\n",
        "    subsample=0.5383447526406704,\n",
        "    colsample_bytree=0.7375702235448874,\n",
        "    max_depth=9,\n",
        "    min_child_weight=4,\n",
        "    eta=0.925350157501082,\n",
        "    gamma=0.8591307262185451,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_cal.fit(X_train, y_train)\n",
        "y_pred = xgb_cal.predict(X_test)\n",
        "mse_xgb_cal = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_cal = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_cal = np.sqrt(mse_xgb_cal)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_cal)+ \" y un MAE igual a \"+str(mae_xgb_cal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 12:43:01,247] A new study created in memory with name: no-name-d14d3ac2-f68f-47af-956f-318aef29e9eb\n",
            "[I 2024-04-21 12:45:19,651] Trial 0 finished with value: 115477217.75042 and parameters: {'lambda': 1.1738823200956587e-06, 'alpha': 0.0017251777585260365, 'subsample': 0.922996261266547, 'colsample_bytree': 0.696063318938529, 'n_estimators': 777, 'max_depth': 9, 'min_child_weight': 8, 'eta': 4.22652728787663e-08, 'gamma': 0.1471061844077492, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 115477217.75042.\n",
            "[I 2024-04-21 12:48:29,499] Trial 1 finished with value: 115467732.85083 and parameters: {'lambda': 8.230955577371347e-07, 'alpha': 2.700095340397065e-06, 'subsample': 0.7719839455531132, 'colsample_bytree': 0.6664030019113035, 'n_estimators': 569, 'max_depth': 5, 'min_child_weight': 5, 'eta': 1.3657559270503528e-05, 'gamma': 6.147125273169158e-07, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 115467732.85083.\n",
            "[I 2024-04-21 12:51:06,117] Trial 2 finished with value: 115404505.76598 and parameters: {'lambda': 3.0358245656082176e-08, 'alpha': 0.03036260285258526, 'subsample': 0.5824522345077436, 'colsample_bytree': 0.2747510185779394, 'n_estimators': 804, 'max_depth': 7, 'min_child_weight': 5, 'eta': 0.0001703086935486815, 'gamma': 0.02883713337082216, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 115404505.76598.\n",
            "[I 2024-04-21 12:53:58,412] Trial 3 finished with value: 89427533.73109 and parameters: {'lambda': 6.989665813272995e-08, 'alpha': 0.9754995163749206, 'subsample': 0.9783358276876455, 'colsample_bytree': 0.24445072505021673, 'n_estimators': 214, 'max_depth': 3, 'min_child_weight': 6, 'eta': 0.11181487244139884, 'gamma': 3.0749897595328207e-07, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 89427533.73109.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  4\n",
            "Best trial:\n",
            "  Value: 89427533.73109\n",
            "  Params: \n",
            "    lambda: 6.989665813272995e-08\n",
            "    alpha: 0.9754995163749206\n",
            "    subsample: 0.9783358276876455\n",
            "    colsample_bytree: 0.24445072505021673\n",
            "    n_estimators: 214\n",
            "    max_depth: 3\n",
            "    min_child_weight: 6\n",
            "    eta: 0.11181487244139884\n",
            "    gamma: 3.0749897595328207e-07\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "# intento # 3, agregando el parámetro n_estimators\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "        # número de árboles en el ensamble\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando Optuna tiene un RMSE igual a 3710.6242470718694 y un MAE igual a 2429.386473849335\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_cal_2 = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.9501091374676599,\n",
        "    alpha=2.2458201898736107e-06,\n",
        "    subsample=0.33554148719968135,\n",
        "    colsample_bytree=0.6131209517619073,\n",
        "    n_estimators= 988,\n",
        "    max_depth=3,\n",
        "    min_child_weight=8,\n",
        "    eta=0.9710181349940284,\n",
        "    gamma=0.0031652899319421076,\n",
        "    grow_policy='depthwise',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_cal_2.fit(X_train, y_train)\n",
        "y_pred = xgb_cal_2.predict(X_test)\n",
        "mse_xgb_cal_2 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_cal_2 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_cal_2 = np.sqrt(mse_xgb_cal_2)\n",
        "print(\"El modelo XGB calibrado usando Optuna tiene un RMSE igual a \" +str(rmse_xgb_cal_2)+ \" y un MAE igual a \"+str(mae_xgb_cal_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-21 12:54:26,122] A new study created in memory with name: no-name-47d590b6-2e26-4abd-9be9-f5a6d9491aea\n",
            "[I 2024-04-21 12:56:57,494] Trial 0 finished with value: 115455644.06918 and parameters: {'lambda': 0.008119632190766394, 'alpha': 0.02438119977365513, 'subsample': 0.2897167851064407, 'colsample_bytree': 0.7655426129863929, 'n_estimators': 575, 'max_depth': 5, 'min_child_weight': 9, 'eta': 2.6111283060085968e-05, 'gamma': 5.150454034388897e-06, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 115455644.06918.\n",
            "[I 2024-04-21 12:59:06,652] Trial 1 finished with value: 114780738.72714 and parameters: {'lambda': 0.0004999103558476247, 'alpha': 0.000675416736866355, 'subsample': 0.5036687862496991, 'colsample_bytree': 0.5548708707000428, 'n_estimators': 265, 'max_depth': 5, 'min_child_weight': 4, 'eta': 0.0011592274565740952, 'gamma': 326.3072679793406, 'grow_policy': 'depthwise'}. Best is trial 1 with value: 114780738.72714.\n",
            "[I 2024-04-21 13:01:00,581] Trial 2 finished with value: 115477217.75042 and parameters: {'lambda': 5.568387801510093e-08, 'alpha': 5.006670206735194e-05, 'subsample': 0.5347160484690535, 'colsample_bytree': 0.5588621968229183, 'n_estimators': 175, 'max_depth': 7, 'min_child_weight': 3, 'eta': 1.2395259996406132e-07, 'gamma': 1.3496309753268236e-06, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 114780738.72714.\n",
            "[I 2024-04-21 13:04:05,338] Trial 3 finished with value: 115477217.75042 and parameters: {'lambda': 0.6441818620966049, 'alpha': 2.1515167165916145e-07, 'subsample': 0.5050823914862342, 'colsample_bytree': 0.565228390974277, 'n_estimators': 979, 'max_depth': 9, 'min_child_weight': 10, 'eta': 2.2264353253936317e-07, 'gamma': 5.707792263869478e-07, 'grow_policy': 'lossguide'}. Best is trial 1 with value: 114780738.72714.\n",
            "[I 2024-04-21 13:05:51,921] Trial 4 finished with value: 100965444.23553 and parameters: {'lambda': 0.02805080036314085, 'alpha': 0.0003157253026229321, 'subsample': 0.7817962059217425, 'colsample_bytree': 0.7991010613532612, 'n_estimators': 599, 'max_depth': 9, 'min_child_weight': 3, 'eta': 0.015717885700360222, 'gamma': 3.6186607484170263, 'grow_policy': 'lossguide'}. Best is trial 4 with value: 100965444.23553.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials:  5\n",
            "Best trial:\n",
            "  Value: 100965444.23553\n",
            "  Params: \n",
            "    lambda: 0.02805080036314085\n",
            "    alpha: 0.0003157253026229321\n",
            "    subsample: 0.7817962059217425\n",
            "    colsample_bytree: 0.7991010613532612\n",
            "    n_estimators: 599\n",
            "    max_depth: 9\n",
            "    min_child_weight: 3\n",
            "    eta: 0.015717885700360222\n",
            "    gamma: 3.6186607484170263\n",
            "    grow_policy: lossguide\n"
          ]
        }
      ],
      "source": [
        "# Intento #4 cambiando los valores del parámetro gamma\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def objective(trial):\n",
        "    data = df_train.drop(['Price'], axis=1).values\n",
        "    target = df_train['Price'].values\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25, random_state=42)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"approx\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": \"gbtree\",  # Fijar el booster como gbtree\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "        # número de árboles en el ensamble\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
        "    }\n",
        "\n",
        "    # Parámetros específicos de gbtree\n",
        "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "    param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "    param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 500, log=True)\n",
        "    param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    mse = mean_squared_error(valid_y, pred_labels)\n",
        "    return mse\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=50, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando Optuna tiene un RMSE igual a 14661.93511503733 y un MAE igual a 3359.0648440740774\n"
          ]
        }
      ],
      "source": [
        "# Definición del modelo XGBoost con los parámetros encontrados por Optuna\n",
        "xgb_2 = XGBRegressor(\n",
        "    reg_lambda=9.564561673448604e-07,\n",
        "    alpha=1.6980413730845048e-05,\n",
        "    subsample=0.2288913151339783,\n",
        "    colsample_bytree=0.9932758875637113,\n",
        "    n_estimators= 699,\n",
        "    max_depth=9,\n",
        "    min_child_weight=5,\n",
        "    eta=0.9676347877899362,\n",
        "    gamma=1.115418460534174e-08,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1\n",
        ")\n",
        "xgb_2.fit(X_train, y_train)\n",
        "y_pred = xgb_2.predict(X_test)\n",
        "mse_xgb_2 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_2 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_2 = np.sqrt(mse_xgb_2)\n",
        "print(\"El modelo XGB calibrado usando Optuna tiene un RMSE igual a \" +str(rmse_xgb_2)+ \" y un MAE igual a \"+str(mae_xgb_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "# Calibración de gamma\n",
        "gamma = np.arange(0, 100, 10 )\n",
        "MSE_2 = []\n",
        "for valor in gamma:\n",
        "    xgb = XGBRegressor(gamma=valor, random_state=1)\n",
        "    MSE_2.append(cross_val_score(xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
        "    MSE_2 = [abs(valor) for valor in MSE_2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'MSE')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(gamma, MSE_2)\n",
        "plt.title(\"Desempeño de XGBoost por cada valor de gamma\")\n",
        "plt.xlabel('gamma')\n",
        "plt.ylabel('MSE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cargar predicciones en Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AuaaUkJnXQWU",
        "outputId": "059224b3-14e9-479a-b522-fc0cbb689d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 300000 entries, 34894 to 121958\n",
            "Columns: 616 entries, Year to Model_xD5dr\n",
            "dtypes: int64(616)\n",
            "memory usage: 1.4 GB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QJknYwT_XQWV",
        "outputId": "1428c820-2146-481a-b6a9-aad3d5bdcc41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Mileage', 'State_ AK', 'State_ AL', 'State_ AR', 'State_ AZ',\n",
              "       'State_ CA', 'State_ CO', 'State_ CT', 'State_ DC',\n",
              "       ...\n",
              "       'Model_Yaris4dr', 'Model_YarisBase', 'Model_YarisLE', 'Model_Yukon',\n",
              "       'Model_Yukon2WD', 'Model_Yukon4WD', 'Model_Yukon4dr', 'Model_tC2dr',\n",
              "       'Model_xB5dr', 'Model_xD5dr'],\n",
              "      dtype='object', length=616)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GH273Up_XQWd"
      },
      "outputs": [],
      "source": [
        "# Codificar variables categóricas en df_test\n",
        "df_test_ = pd.get_dummies(df_test, columns=categorical_columns).astype(int)\n",
        "\n",
        "# Alinear las columnas de df_test con X_train\n",
        "df_test_aligned, _ = df_test_.align(X_train, axis=1, fill_value=0)\n",
        "\n",
        "column_order = X_train.columns.tolist()\n",
        "\n",
        "# Reordenar las columnas de df_test_aligned de acuerdo con el orden en X_train\n",
        "df_test_ordenado = df_test_aligned[column_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sR6rRk4vXQWe",
        "outputId": "ecc6eb21-29f7-4694-fd91-2b476265db41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Mileage', 'State_ AK', 'State_ AL', 'State_ AR', 'State_ AZ',\n",
              "       'State_ CA', 'State_ CO', 'State_ CT', 'State_ DC',\n",
              "       ...\n",
              "       'Model_Yaris4dr', 'Model_YarisBase', 'Model_YarisLE', 'Model_Yukon',\n",
              "       'Model_Yukon2WD', 'Model_Yukon4WD', 'Model_Yukon4dr', 'Model_tC2dr',\n",
              "       'Model_xB5dr', 'Model_xD5dr'],\n",
              "      dtype='object', length=616)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test_ordenado.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4usiAcIJXQWg",
        "outputId": "f23f280f-6cae-4d60-bd89-10708ed029b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a 3903.2092890134386 y un MAE igual a 2568.201309489746\n"
          ]
        }
      ],
      "source": [
        "# El modelo montado en Kaggle fue:\n",
        "xgb_calibrado_3 = XGBRegressor(\n",
        "    booster='gbtree',\n",
        "    reg_lambda=0.30212357583678445,\n",
        "    alpha=0.18211410327397226,\n",
        "    subsample=0.3521449713976327,\n",
        "    colsample_bytree=0.44811953613366806,\n",
        "    max_depth=9,\n",
        "    min_child_weight=9,\n",
        "    eta=0.8918833748094722,\n",
        "    gamma=0.00034064735565798957,\n",
        "    grow_policy='lossguide',\n",
        "    random_state=1  # Si deseas mantener una semilla aleatoria fija\n",
        ")\n",
        "xgb_calibrado_3.fit(X_train, y_train)\n",
        "y_pred = xgb_calibrado_3.predict(X_test)\n",
        "mse_xgb_calibrado_3 = mean_squared_error(y_test, y_pred)\n",
        "mae_xgb_calibrado_3 = mean_absolute_error(y_test, y_pred)\n",
        "rmse_xgb_calibrado_3 = np.sqrt(mse_xgb_calibrado_3)\n",
        "print(\"El modelo XGB calibrado usando GreedSearch tiene un RMSE igual a \" +str(rmse_xgb_calibrado_3)+ \" y un MAE igual a \"+str(mae_xgb_calibrado_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se usa df_test_aligned para predecir\n",
        "y_pred = xgb_cal.predict(df_test_ordenado)\n",
        "\n",
        "predictions_df = pd.DataFrame(y_pred, index=df_test_ordenado.index, columns=['Price'])\n",
        "\n",
        "predictions_df.to_csv('predicciones.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
